==========================================
Guide d'utilisation - SleepDisorderDetect
==========================================

:Auteur: AMRI Maryam Et BOUGHNAM Houda
:Date: 21/05/2025
:Version: 1.0.0
:Contact: amrimaryam780@gmail.com

.. contents:: Table des mati√®res
   :depth: 2
   :backlinks: none

Projet de d√©tection des troubles du sommeil bas√© sur l'analyse de PSG
====================================================================

Ce guide d√©taill√© explique comment utiliser le projet de d√©tection des troubles 
du sommeil √† partir de donn√©es polysomnographiques (PSG) au format `.edf`. 
Le syst√®me analyse les signaux physiologiques pour identifier trois troubles 
principaux : l'insomnie, l'apn√©e du sommeil et la narcolepsie.

Pr√©requis
=========

Avant de commencer, assurez-vous d'avoir :

* Un compte Kaggle avec acc√®s aux notebooks
* Connaissance de base de Python et des notebooks Jupyter
* Un fichier PSG au format `.edf` (par exemple de la base de donn√©es Sleep-EDF)
* Acc√®s √† internet pour le chargement des biblioth√®ques n√©cessaires

Utilisation du notebook Kaggle
=============================

Le projet est enti√®rement impl√©ment√© dans un notebook Kaggle. Pour l'utiliser :

1. Acc√©dez au notebook via le lien fourni ou copiez-le dans votre espace Kaggle
2. T√©l√©chargez votre fichier `.edf` dans l'espace de donn√©es Kaggle
3. Ex√©cutez les cellules du notebook dans l'ordre

Structure du notebook
===================

Le notebook est organis√© en sections correspondant aux diff√©rentes √©tapes du pipeline de traitement :

::

    1. Configuration et importation des biblioth√®ques
    2. Chargement des fichiers .edf
    3. Transformation des signaux en CSV
    4. Pr√©traitement des donn√©es
    5. Pr√©diction des signaux (EEG et EMG)
    6. D√©tection des troubles du sommeil
    7. Visualisation des r√©sultats

√âtapes d√©taill√©es du pipeline
============================

1. Importation du fichier `.edf`
----------------------------------

Dans cette section du notebook, vous importez votre fichier PSG au format `.edf`.

*Code √† ex√©cuter dans le notebook* :

.. code-block:: python


    import mne
    import os
    
    # Sp√©cifiez le chemin vers votre fichier .edf
    edf_file = '../input/sleep-edf-database-expanded/SC4001E0-PSG.edf'
    
    # Chargement du fichier EDF
    raw = mne.io.read_raw_edf(edf_file, preload=True)
    
    # Affichage des informations sur les canaux disponibles
    print(raw.info)
    
    # Liste des canaux disponibles
    print("Canaux disponibles:", raw.ch_names)

**R√©sultat attendu** :
- Affichage des canaux disponibles dans le fichier EDF
- Confirmation que les signaux EEG (Fpz-Cz), EMG et EOG sont pr√©sents
- Affichage des caract√©ristiques des signaux (fr√©quence d'√©chantillonnage, etc.)

**Conseils** :
- V√©rifiez que les canaux EEG, EMG et EOG sont correctement identifi√©s
- Assurez-vous que la fr√©quence d'√©chantillonnage est suffisante (g√©n√©ralement 100 Hz)

2. Transformation en CSV
-----------------------

Cette section du notebook convertit les signaux bruts du fichier ``.edf`` en DataFrames pandas pour faciliter l'analyse.

*Code √† ex√©cuter dans le notebook* :

.. code-block:: python

    import pandas as pd
    import numpy as np

    # Extraire les signaux en DataFrames
    eeg_data = raw.get_data(picks=['EEG Fpz-Cz'])
    emg_data = raw.get_data(picks=['EMG submental'])
    eog_data = raw.get_data(picks=['EOG horizontal'])

    # Cr√©er des DataFrames pandas
    sampling_freq = raw.info['sfreq']
    times = np.arange(0, len(eeg_data[0])) / sampling_freq

    eeg_df = pd.DataFrame({
    'timestamp': times,
    'value': eeg_data[0],
    'channel': 'EEG Fpz-Cz'
    })

    emg_df = pd.DataFrame({
    'timestamp': times,
    'value': emg_data[0],
    'channel': 'EMG submental'
    })

    eog_df = pd.DataFrame({
    'timestamp': times,
    'value': eog_data[0],
    'channel': 'EOG horizontal'
    })

   # Sauvegarder en CSV si n√©cessaire (optionnel dans Kaggle)
   eeg_df.to_csv('eeg.csv', index=False)
   emg_df.to_csv('emg.csv', index=False)
   eog_df.to_csv('eog.csv', index=False)

   # Afficher les premi√®res lignes pour v√©rification
   print("Donn√©es EEG:")
   print(eeg_df.head())

   # Fusionner tous les signaux dans une seule DataFrame
  dftotal = pd.concat([eeg_df, emg_df, eog_df], ignore_index=True)

  # Afficher les premi√®res lignes de la DataFrame fusionn√©e
  print("\nDonn√©es fusionn√©es (dftotal):")
  print(dftotal.head())

  # Sauvegarder la DataFrame fusionn√©e en CSV si n√©cessaire
  dftotal.to_csv('all_signals.csv', index=False)

*R√©sultat attendu* :
- Cr√©ation de trois DataFrames contenant les signaux EEG, EMG et EOG
- Structure des DataFrames avec colonnes : timestamp, value, channel
- Affichage des premi√®res lignes de donn√©es pour v√©rification
- Creation d'une dataframe dftotal qui contient tous les signaux
3. Pr√©traitement des donn√©es
---------------------------

Cette section du notebook nettoie et pr√©pare les donn√©es pour l'analyse.

*Code √† ex√©cuter* :

.. code-block:: python


    import statsmodels.api as sm
    import pandas as pd
    from sklearn.preprocessing import MinMaxScaler
    import matplotlib.pyplot as plt
    dftotal.isna().sum()
    dftotal.dropna(inplace=True)
    
    sm.qqplot(dftotal.Label, line='s')
    sm.qqplot(dftotal["EEG Fpz-Cz"], line='s')

    # Supposons que votre DataFrame est dftotal
    colonnes_signaux = ['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'EMG submental']

    # Initialiser le MinMaxScaler (par d√©faut, mise √† l'√©chelle entre 0 et 1)
    scaler = MinMaxScaler()

    # Appliquer la normalisation aux colonnes s√©lectionn√©es
    dftotal[colonnes_signaux] = scaler.fit_transform(dftotal[colonnes_signaux])
    
    dftotal['EEG Fpz-Cz'].plot(title="EEG Fpz-Cz	",figsize=(20,5))
    plt.show()
    
    dftotal['EEG Pz-Oz'].plot(title="EEG Pz-Oz",figsize=(20,5))
    plt.show()
  
    dftotal['EOG horizontal'].plot(title="EOG horizontal",figsize=(20,5))
    plt.show() 


*R√©sultat attendu* :
- DataFrames pr√©trait√©s avec :
  - Pas de valeurs manquantes
  - Signal normalis√© 
  - Graphiques montrant les signaux  apr√®s pr√©traitement

  .. image:: _static/images/avant.png
    :alt: Avant le pretraitement 
    :width: 500px

  .. image:: _static/images/apres.png
    :alt: Apres le pretraitement 
    :width: 500px

4. Pr√©diction du signal EMG
--------------------------

Cette section pr√©sente une approche avanc√©e pour analyser le signal EMG afin de d√©tecter des mouvements anormaux. Le syst√®me utilise des techniques d'apprentissage profond pour mod√©liser les patterns complexes pr√©sents dans les signaux c√©r√©braux.

### Composantes principales

1. *Pr√©traitement des donn√©es*: Normalisation des signaux EEG bruts
2. *Extraction de caract√©ristiques*: Calcul de m√©triques statistiques, fr√©quentielles et de complexit√©
3. *Mod√©lisation hybride*: Combinaison de couches convolutives et LSTM bidirectionnelles
4. *Pr√©diction adaptative*: G√©n√©ration de signaux EEG futurs avec maintien des propri√©t√©s statistiques

Section 1: Configuration et importation des biblioth√®ques
--------------------------------------------------------

.. code-block:: python

    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.metrics import mean_squared_error
    import tensorflow as tf
    from tensorflow.keras.models import Sequential, Model
    from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Conv1D, MaxPooling1D, Input
    from tensorflow.keras.layers import LayerNormalization, GaussianNoise, Concatenate, Add, GlobalAveragePooling1D
    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
    from tensorflow.keras.optimizers import Adam
    import seaborn as sns

    # Configuration pour am√©liorer les performances
    physical_devices = tf.config.list_physical_devices('GPU')
    if physical_devices:
        tf.config.experimental.set_memory_growth(physical_devices[0], True)

    # D√©finir les param√®tres de graines al√©atoires pour la reproductibilit√©
    np.random.seed(42)
    tf.random.set_seed(42)

Cette section importe toutes les biblioth√®ques n√©cessaires pour le traitement des donn√©es, la cr√©ation de mod√®les deep learning et la visualisation. Elle configure √©galement le GPU pour une utilisation optimale de la m√©moire et d√©finit des graines al√©atoires pour assurer la reproductibilit√© des r√©sultats.

Section 2: Pr√©paration des donn√©es
----------------------------------

.. code-block:: python

    # V√©rifier si dftotal existe, sinon cr√©er des donn√©es synth√©tiques pour test
    try:
        eeg_data = dftotal['EMG submental'].values  # Utilisation de vos donn√©es
    except NameError:
        print("Variable 'dftotal' not found. Creating synthetic data for testing...")
        # G√©n√©rer des donn√©es EMG synth√©tiques pour test
        n_samples = 3000
        t = np.linspace(0, 30, n_samples)
        eeg_data = np.sin(0.5*t) + 0.2*np.sin(2.5*t) + 0.1*np.sin(7.5*t) + 0.05*np.random.randn(n_samples)

    # Param√®tres du mod√®le - optimis√©s pour pr√©server les fluctuations
    sequence_length = 30  # Raccourci pour capturer les oscillations √† plus haute fr√©quence
    pred_length = 1  # Pr√©dire un point √† la fois
    stride = 1  # Augmenter le nombre d'exemples d'entra√Ænement
    batch_size = 32  # Petit batch pour meilleur ajustement
    epochs = 50  # Plus d'epochs pour un apprentissage plus fin

    # Normalisation des donn√©es - StandardScaler peut √™tre pr√©f√©rable pour pr√©server les variations
    scaler = MinMaxScaler(feature_range=(0, 1))
    eeg_data_scaled = scaler.fit_transform(eeg_data.reshape(-1, 1)).flatten()

    # √âchantillonnage des donn√©es
    sample_size = min(150000, len(eeg_data_scaled))  # S'assurer que sample_size n'est pas sup√©rieur √† la taille des donn√©es
    eeg_sample = eeg_data_scaled[:sample_size]

Ce code pr√©pare les donn√©es EMG pour l'analyse. Il tente d'abord d'utiliser les donn√©es r√©elles (depuis `dftotal`), mais g√©n√®re des donn√©es synth√©tiques si n√©cessaire. Les donn√©es sont ensuite normalis√©es avec MinMaxScaler pour ramener toutes les valeurs entre 0 et 1, ce qui facilite l'apprentissage du mod√®le.

Section 3: Fonction d'extraction de caract√©ristiques
---------------------------------------------------

.. code-block:: python

    def extract_features(data, seq_length):
        """Extraire des caract√©ristiques avanc√©es du signal EMG"""
        features = []
        
        # V√©rifier que les donn√©es ont une forme correcte
        if len(data.shape) > 1 and data.shape[0] == 1:
            data = data.flatten()
        
        # V√©rifier que la s√©quence est assez longue
        if len(data) < seq_length:
            print(f"Warning: Data length {len(data)} is less than sequence length {seq_length}")
            # Padding si n√©cessaire
            if len(data) > 0:
                padding = np.zeros(seq_length - len(data))
                data = np.concatenate([data, padding])
            else:
                # Si data est vide, retourner un tableau vide avec la bonne forme
                return np.zeros((0, 11))
        
        for i in range(len(data) - seq_length + 1):
            segment = data[i:i+seq_length]
            
            # Caract√©ristiques statistiques
            mean = np.mean(segment)
            std = np.std(segment)
            min_val = np.min(segment)
            max_val = np.max(segment)
            range_val = max_val - min_val
            
            # Tendance et variation
            gradient = np.gradient(segment).mean()
            abs_gradient = np.abs(np.gradient(segment)).mean()  # Mesure de la variabilit√© globale
            
            # Analyse fr√©quentielle
            fft_vals = np.abs(np.fft.rfft(segment))
            # S'assurer que fft_vals a au moins un √©l√©ment avant d'acc√©der √† l'index 1
            if len(fft_vals) > 1:
                dominant_freq_idx = np.argmax(fft_vals[1:]) + 1  # Ignorer DC (indice 0)
                dominant_freq_val = fft_vals[dominant_freq_idx] / len(segment)
            else:
                dominant_freq_val = 0
            
            # Entropie approximative (mesure de la complexit√©/r√©gularit√©)
            # Version simplifi√©e, consid√©rez une impl√©mentation plus compl√®te au besoin
            diffs = np.diff(segment)
            direction_changes = np.sum(np.diff(np.signbit(diffs)) != 0)
            complexity = direction_changes / max(1, (seq_length - 2))  # √âviter division par z√©ro
            
            # Caract√©ristiques de forme d'onde
            peak_count = len(np.where(np.diff(np.signbit(np.diff(segment))) < 0)[0])  # Nombre de pics
            zero_crossings = len(np.where(np.diff(np.signbit(segment)))[0])  # Nombre de passages √† z√©ro
            
            # Regrouper toutes les caract√©ristiques
            feature_vec = np.array([
                mean, std, min_val, max_val, range_val, 
                gradient, abs_gradient, 
                dominant_freq_val, complexity,
                peak_count / max(1, seq_length), zero_crossings / max(1, seq_length)  # √âviter division par z√©ro
            ])
            
            features.append(feature_vec)
        
        return np.array(features)

Cette fonction extrait des caract√©ristiques avanc√©es du signal EMG qui aideront le mod√®le √† mieux capturer la complexit√© des donn√©es. Les caract√©ristiques incluent:
- Statistiques de base (moyenne, √©cart-type, min, max, range)
- Mesures de tendance et variation (gradient moyen, gradient absolu moyen)
- Analyse fr√©quentielle (fr√©quence dominante)
- Mesures de complexit√© (entropie approximative)
- Caract√©ristiques de forme d'onde (nombre de pics, passages √† z√©ro)

Section 4: Cr√©ation de s√©quences enrichies
------------------------------------------

.. code-block:: python

    def create_enriched_sequences(data, seq_length, pred_length=1, stride=1):
        """Cr√©e des s√©quences d'entr√©e/sortie avec des caract√©ristiques enrichies"""
        X_raw, y = [], []
        
        # V√©rifier que les donn√©es sont suffisantes
        if len(data) <= seq_length + pred_length:
            print(f"Warning: Data length {len(data)} is not sufficient for sequence length {seq_length} and prediction length {pred_length}")
            return np.array([]), np.array([]), np.array([])
        
        for i in range(0, len(data) - seq_length - pred_length + 1, stride):
            X_raw.append(data[i:i + seq_length])
            if pred_length == 1:
                y.append(data[i + seq_length])
            else:
                y.append(data[i + seq_length:i + seq_length + pred_length])
        
        X_raw = np.array(X_raw)
        
        # V√©rifier que X_raw n'est pas vide avant d'extraire les caract√©ristiques
        if len(X_raw) == 0:
            return np.array([]), np.array([]), np.array([])
        
        # Extraire des caract√©ristiques suppl√©mentaires
        X_features = extract_features(data, seq_length)
        
        # S'assurer que X_features et X_raw ont le m√™me nombre d'√©chantillons
        min_samples = min(len(X_raw), len(X_features))
        if min_samples == 0:
            return np.array([]), np.array([]), np.array([])
        
        X_raw = X_raw[:min_samples]
        X_features = X_features[:min_samples]
        y = np.array(y)[:min_samples]
        
        return X_raw, X_features, y

    # Cr√©er des s√©quences avec caract√©ristiques enrichies
    X_raw, X_features, y = create_enriched_sequences(eeg_sample, sequence_length, pred_length, stride)

    # V√©rifier que les donn√©es ne sont pas vides
    if len(X_raw) == 0 or len(X_features) == 0 or len(y) == 0:
        raise ValueError("Sequences could not be created. Check your data and parameters.")

    X_raw = X_raw.reshape((X_raw.shape[0], X_raw.shape[1], 1))

    print(f"Forme des donn√©es brutes: {X_raw.shape}")
    print(f"Forme des caract√©ristiques: {X_features.shape}")
    print(f"Forme des donn√©es de sortie: {y.shape}")

Cette fonction transforme les donn√©es EMG en s√©quences temporelles utilisables par un mod√®le de deep learning. Pour chaque fen√™tre de donn√©es (de longueur `sequence_length`), elle extrait:
1. La s√©quence brute des valeurs EMG
2. Des caract√©ristiques avanc√©es calcul√©es √† partir de cette s√©quence
3. La valeur cible √† pr√©dire (le point suivant)

Le code cr√©e √©galement ces s√©quences √† partir des donn√©es d'√©chantillon et affiche leurs dimensions.

Section 5: Division des donn√©es
------------------------------

.. code-block:: python

    # Division en ensembles d'entra√Ænement et de test
    train_size = int(len(X_raw) * 0.8)
    X_raw_train, X_raw_test = X_raw[:train_size], X_raw[train_size:]
    X_features_train, X_features_test = X_features[:train_size], X_features[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]

    # V√©rifier qu'il y a suffisamment de donn√©es pour validation
    if train_size < 5:
        raise ValueError(f"Not enough training data. Train size: {train_size}")

    # Cr√©ation d'un ensemble de validation
    val_size = max(1, int(train_size * 0.2))  # Au moins 1 √©chantillon pour validation
    X_raw_val, X_features_val, y_val = X_raw_train[-val_size:], X_features_train[-val_size:], y_train[-val_size:]
    X_raw_train, X_features_train, y_train = X_raw_train[:-val_size], X_features_train[:-val_size], y_train[:-val_size]

Ce code divise les donn√©es en trois ensembles:
- Ensemble d'entra√Ænement (64% des donn√©es): utilis√© pour entra√Æner le mod√®le
- Ensemble de validation (16% des donn√©es): utilis√© pour ajuster les hyperparam√®tres et √©viter le surapprentissage
- Ensemble de test (20% des donn√©es): utilis√© pour √©valuer les performances finales du mod√®le

Section 6: Cr√©ation du mod√®le avanc√©
------------------------------------

.. code-block:: python

    def create_advanced_emg_model(seq_length, feature_dim):
        """
        Mod√®le hybride optimis√© pour capturer la complexit√© des signaux EMG
        """
        # Entr√©e pour la s√©quence brute
        input_seq = Input(shape=(seq_length, 1))
        
        # Entr√©e pour les caract√©ristiques extraites
        input_features = Input(shape=(feature_dim,))
        
        # --- Branche de convolution multi-√©chelle ---
        # Ajouter du bruit subtil pour am√©liorer la g√©n√©ralisation
        x = GaussianNoise(0.005)(input_seq)
        
        # Convolutions parall√®les avec diff√©rentes tailles de noyau pour capturer diff√©rentes √©chelles
        conv_kernels = [2, 3, 5, 7]
        conv_outputs = []
        
        for kernel_size in conv_kernels:
            # S'assurer que kernel_size n'est pas plus grand que la s√©quence
            if kernel_size <= seq_length:
                conv = Conv1D(
                    filters=32, 
                    kernel_size=kernel_size,
                    padding='same',
                    activation='elu'  # ELU peut √™tre meilleur pour pr√©server les variations subtiles
                )(x)
                conv = LayerNormalization()(conv)  # Normalisation pour stabiliser l'entra√Ænement
                conv_outputs.append(conv)
        
        # V√©rifier qu'il y a des sorties de convolution
        if not conv_outputs:
            raise ValueError(f"All kernel sizes {conv_kernels} are larger than sequence length {seq_length}")
            
        # Concat√©ner les sorties de convolution
        x = Concatenate()(conv_outputs)
        
        # Convolutions dilat√©es pour capturer des d√©pendances √† long terme
        dilation_rates = [1, 2, 4, 8]
        dilated_outputs = []
        
        for dilation_rate in dilation_rates:
            # V√©rifier que la dilatation n'est pas trop grande pour la s√©quence
            if (3 - 1) * dilation_rate + 1 <= seq_length:  # Taille effective = (kernel_size - 1) * dilation_rate + 1
                dilated_conv = Conv1D(
                    filters=32, 
                    kernel_size=3, 
                    padding='causal', 
                    dilation_rate=dilation_rate,
                    activation='elu'
                )(x)
                dilated_outputs.append(dilated_conv)
        
        # V√©rifier qu'il y a des sorties dilat√©es
        if not dilated_outputs:
            # Utiliser une convolution simple si aucune dilatation ne convient
            dilated_conv = Conv1D(
                filters=32, 
                kernel_size=1,  # Kernel size 1 fonctionnera toujours
                activation='elu'
            )(x)
            dilated_outputs.append(dilated_conv)
            
        # Combiner les convolutions dilat√©es
        x = Concatenate()(dilated_outputs)
        x = Conv1D(64, kernel_size=1, activation='elu')(x)  # R√©duction de dimension
        
        # --- Branche LSTM bidirectionnelle ---
        lstm_out = Bidirectional(LSTM(64, return_sequences=True))(x)
        lstm_out = LayerNormalization()(lstm_out)
        lstm_out = Dropout(0.3)(lstm_out)  # Dropout un peu plus √©lev√© pour √©viter le surapprentissage
        lstm_out = Bidirectional(LSTM(48, return_sequences=False))(lstm_out)
        
        # --- Traitement des caract√©ristiques ---
        # Passer les caract√©ristiques par des couches denses pour un meilleur apprentissage
        features_dense = Dense(32, activation='elu')(input_features)
        features_dense = Dense(32, activation='elu')(features_dense)
        
        # --- Fusion des branches ---
        combined = Concatenate()([lstm_out, features_dense])
        
        # Couches de sortie 
        x = Dense(64, activation='elu')(combined)
        x = Dropout(0.2)(x)
        x = Dense(32, activation='elu')(x)
        
        # Couche de sortie - pas d'activation pour la r√©gression
        output = Dense(pred_length)(x)
        
        # Cr√©er le mod√®le
        model = Model(inputs=[input_seq, input_features], outputs=output)
        
        # Optimiseur avec taux d'apprentissage adaptatif et clippage de gradient
        optimizer = Adam(learning_rate=0.001, clipnorm=1.0)
        model.compile(optimizer=optimizer, loss='mse')
        
        return model

    # Cr√©er le mod√®le am√©lior√©
    model = create_advanced_emg_model(sequence_length, X_features.shape[1])
    model.summary()

Cette fonction cr√©e un mod√®le de deep learning hybride sophistiqu√© pour la pr√©vision de signaux EMG. Le mod√®le comprend:

1. Une branche de convolution multi-√©chelle avec:
   - Des convolutions parall√®les de diff√©rentes tailles pour capturer des motifs √† diff√©rentes √©chelles
   - Des convolutions dilat√©es pour saisir des d√©pendances √† long terme

2. Une branche LSTM bidirectionnelle pour capturer les motifs temporels complexes

3. Une branche dense pour traiter les caract√©ristiques extraites

4. Une fusion des branches pour combiner toutes les informations avant la pr√©diction finale

Cette architecture avanc√©e permet de capturer efficacement la complexit√© des signaux EMG.

Section 7: Entra√Ænement du mod√®le
--------------------------------

.. code-block:: python

    # Callbacks pour l'entra√Ænement avec sauvegarde et r√©duction du taux d'apprentissage
    early_stopping = EarlyStopping(
        monitor='val_loss', 
        patience=15, 
        restore_best_weights=True,
        verbose=1
    )
    model_checkpoint = ModelCheckpoint(
        'best_emg_model.keras', 
        save_best_only=True, 
        monitor='val_loss',
        verbose=1
    )
    reduce_lr = ReduceLROnPlateau(
        monitor='val_loss', 
        factor=0.5, 
        patience=6, 
        min_lr=0.00001,
        verbose=1
    )

    # Entra√Ænement du mod√®le
    history = model.fit(
        [X_raw_train, X_features_train], y_train,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=([X_raw_val, X_features_val], y_val),
        callbacks=[early_stopping, model_checkpoint, reduce_lr],
        verbose=1
    )

Ce code entra√Æne le mod√®le avec plusieurs callbacks pour optimiser le processus:
- `EarlyStopping`: arr√™te l'entra√Ænement si la performance ne s'am√©liore pas pendant 15 √©poques
- `ModelCheckpoint`: sauvegarde la meilleure version du mod√®le
- `ReduceLROnPlateau`: r√©duit le taux d'apprentissage si la performance stagne

Section 8: Visualisation de l'apprentissage
------------------------------------------

.. code-block:: python

    # Visualisation de la courbe d'apprentissage
    plt.figure(figsize=(15, 5))
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('√âvolution de la perte pendant l\'entra√Ænement')
    plt.xlabel('√âpoques')
    plt.ylabel('Perte (MSE)')
    plt.legend()
    plt.grid(True)
    plt.savefig('emg_training_loss.png')
    plt.close()

.. image:: _static/images/emg_training_loss.png
     :alt: Resultat De training loss EMG 
     :width: 500px
Ce code cr√©e et sauvegarde un graphique montrant l'√©volution de l'erreur d'entra√Ænement et de validation au fil des √©poques, permettant de visualiser le processus d'apprentissage et de d√©tecter d'√©ventuels probl√®mes comme le surapprentissage.

Section 9: √âvaluation du mod√®le
------------------------------

.. code-block:: python

    # V√©rifier qu'il y a des donn√©es de test avant de pr√©dire
    if len(X_raw_test) == 0:
        raise ValueError("No test data available")

    # Pr√©diction sur l'ensemble de test
    y_pred = model.predict([X_raw_test, X_features_test])

    # Inverser la normalisation pour obtenir les valeurs r√©elles
    if pred_length == 1:
        y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
        y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()
    else:
        y_test_inv = np.array([scaler.inverse_transform(y.reshape(-1, 1)).flatten() for y in y_test])
        y_pred_inv = np.array([scaler.inverse_transform(y.reshape(-1, 1)).flatten() for y in y_pred])

    # Calcul de l'erreur
    mse = mean_squared_error(y_test_inv, y_pred_inv)
    rmse = np.sqrt(mse)
    print(f"Erreur quadratique moyenne (MSE): {mse}")
    print(f"Racine de l'erreur quadratique moyenne (RMSE): {rmse}")

.. image:: _static/images/performancesEMG.png
     :alt: Resultat d'evaluation de Performances 
     :width: 500px

Ce code √©value les performances du mod√®le sur l'ensemble de test:
1. Il g√©n√®re des pr√©dictions pour les donn√©es de test
2. Inverse la normalisation pour obtenir des valeurs dans l'√©chelle originale
3. Calcule et affiche l'erreur quadratique moyenne (MSE) et sa racine carr√©e (RMSE)

Section 10: Fonction de pr√©vision r√©aliste
-----------------------------------------

.. code-block:: python

    def forecast_realistic_emg(model, initial_sequence, steps_ahead=200, scaler=None):
        """
        Pr√©vision r√©aliste de signal EMG qui recalcule les caract√©ristiques √† chaque √©tape
        et utilise une approche adaptative pour maintenir la naturalit√© du signal
        """
        sequence_length = initial_sequence.shape[0]
        future_predictions = []
        
        # S√©quence courante pour la pr√©diction it√©rative
        current_sequence = initial_sequence.flatten().copy()
        
        # V√©rifier qu'il y a assez de points dans la s√©quence
        if len(current_sequence) < 10:
            print(f"Warning: Initial sequence has only {len(current_sequence)} points, padding with zeros")
            padding = np.zeros(10 - len(current_sequence))
            current_sequence = np.concatenate([current_sequence, padding])
        
        # Historique r√©cent des variations pour maintenir la coh√©rence
        recent_variations = np.diff(current_sequence[-10:])
        variation_history = np.abs(recent_variations).mean()
        
        for i in range(steps_ahead):
            # V√©rifier que la s√©quence actuelle est de la bonne longueur
            if len(current_sequence) < sequence_length:
                padding = np.zeros(sequence_length - len(current_sequence))
                temp_sequence = np.concatenate([current_sequence, padding])
            else:
                temp_sequence = current_sequence[-sequence_length:]
            
            # Extraire les caract√©ristiques de la s√©quence actuelle
            try:
                # S'assurer que extract_features re√ßoit un tableau non vide
                if len(temp_sequence) == 0:
                    raise ValueError("Empty sequence for feature extraction")
                    
                current_features_array = extract_features(temp_sequence, sequence_length)
                
                # V√©rifier que les caract√©ristiques sont extraites correctement
                if len(current_features_array) == 0:
                    raise ValueError("Feature extraction returned empty array")
                    
                current_features = current_features_array[0]
            except Exception as e:
                print(f"Error extracting features: {e}")
                # Utiliser des caract√©ristiques par d√©faut
                current_features = np.zeros(X_features.shape[1])
            
            # Pr√©dire le prochain point
            next_point_scaled = model.predict(
                [temp_sequence.reshape(1, sequence_length, 1), 
                 current_features.reshape(1, -1)]
            )[0][0]
            
            # Stabilit√© adaptative: si la pr√©diction s'√©carte trop de la tendance r√©cente,
            # appliquer une correction subtile
            last_point = current_sequence[-1]
            max_jump = 2.5 * variation_history  # Limite bas√©e sur la volatilit√© historique
            
            # Limiter les sauts trop grands tout en pr√©servant la direction
            if abs(next_point_scaled - last_point) > max_jump:
                direction = np.sign(next_point_scaled - last_point)
                next_point_scaled = last_point + direction * max_jump
            
            # Ajouter un peu de bruit adaptatif bas√© sur la volatilit√© du signal
            # Plus le signal √©tait volatile, plus on permet de fluctuations
            noise_scale = variation_history * 0.5  # La fluctuation est proportionnelle √† la volatilit√© historique
            # G√©rer le cas o√π variation_history est 0 ou NaN
            if not np.isfinite(noise_scale) or noise_scale == 0:
                noise_scale = 0.01  # Valeur par d√©faut
                
            noise = np.random.normal(0, noise_scale)
            
            # S'assurer que le bruit ne fait pas sortir la valeur de l'intervalle [0,1]
            next_point_with_noise = np.clip(next_point_scaled + noise, 0, 1)
            
            # Ajouter √† nos pr√©dictions
            future_predictions.append(next_point_with_noise)
            
            # Mettre √† jour la s√©quence pour la prochaine pr√©diction
            current_sequence = np.append(current_sequence[1:], next_point_with_noise)
            
            # Mettre √† jour l'historique des variations pour l'adaptativit√©
            if i >= 1:
                new_variation = abs(future_predictions[-1] - future_predictions[-2])
                # Moyenne mobile exponentielle pour l'historique des variations
                variation_history = 0.85 * variation_history + 0.15 * new_variation
        
        # Convertir les pr√©dictions en array numpy
        future_predictions = np.array(future_predictions)
        
        # Inverser la normalisation si un scaler est fourni
        if scaler is not None:
            future_predictions = scaler.inverse_transform(future_predictions.reshape(-1, 1)).flatten()
        
        return future_predictions

Cette fonction sophistiqu√©e permet de g√©n√©rer des pr√©visions futures r√©alistes pour les signaux EMG. Ses principales caract√©ristiques:

1. Recalcul des caract√©ristiques √† chaque √©tape: contrairement √† une simple pr√©diction, elle recalcule les caract√©ristiques pour chaque nouvelle pr√©diction

2. Stabilit√© adaptative: limite les sauts trop importants entre les valeurs cons√©cutives en se basant sur la volatilit√© historique du signal

3. Bruit adaptatif: ajoute un bruit r√©aliste proportionnel √† la variabilit√© naturelle du signal

4. Mise √† jour dynamique: ajuste la volatilit√© attendue en fonction des nouvelles pr√©dictions

Cette approche garantit des pr√©visions qui semblent naturelles et respectent les caract√©ristiques statistiques du signal EMG original.

Section 11: Visualisation des motifs r√©els
-----------------------------------------

.. code-block:: python

    # V√©rifier qu'il y a des donn√©es de test avant de visualiser
    if len(y_test_inv) < 100:
        print("Warning: Not enough test data for visualization. Using available data.")
        visualize_length = min(5, len(y_test_inv))
    else:
        visualize_length = 5

    # Visualiser quelques exemples de s√©quences r√©elles pour comprendre la variabilit√©
    plt.figure(figsize=(15, 5))
    for i in range(visualize_length):  # Afficher 5 s√©quences d'exemple (ou moins si pas assez de donn√©es)
        # S'assurer que l'index est valide
        max_start = max(0, len(y_test_inv) - 100)
        if max_start > 0:
            start_idx = np.random.randint(0, max_start)
            plot_length = min(100, len(y_test_inv) - start_idx)
            plt.plot(y_test_inv[start_idx:start_idx+plot_length], alpha=0.7)
        else:
            # Si pas assez de donn√©es, utiliser tout ce qui est disponible
            plt.plot(y_test_inv, alpha=0.7)

    plt.title('Exemples de s√©quences EMG r√©elles (pour comprendre la variabilit√©)')
    plt.xlabel('Points temporels')
    plt.ylabel('Amplitude EMG')
    plt.grid(True)
    plt.savefig('emg_real_patterns.png')
    plt.close()

.. image:: _static/images/emg_real_patterns.png
     :alt: EMG real patterns 
     :width: 500px

Ce code visualise quelques segments du signal EMG r√©el pour comprendre sa variabilit√© naturelle. Il s√©lectionne al√©atoirement 5 segments (ou moins si les donn√©es sont insuffisantes) et les affiche sur un m√™me graphique.

Section 12: G√©n√©ration et visualisation des pr√©visions futures
------------------------------------------------------------

.. code-block:: python

    if len(y_test_inv) < 100:
      real_history_length = len(y_test_inv)
      print(f"Warning: Only {real_history_length} real data points available for visualization")
    else:
    real_history_length = 100

    # Visualiser les pr√©dictions futures r√©alistes
    plt.figure(figsize=(15, 6))

    # Afficher les derni√®res valeurs r√©elles disponibles
    real_history = y_test_inv[-real_history_length:]
    plt.plot(range(real_history_length), real_history, label='Donn√©es EMG r√©elles', color='blue')

    # Afficher les pr√©dictions futures
    plt.plot(range(real_history_length-1, real_history_length-1+future_steps), future_predictions, 
         label='Pr√©dictions futures', color='red', linestyle='--')
    plt.axvline(x=real_history_length-1, color='green', linestyle='-', label='Pr√©sent')

    plt.title('Pr√©vision future r√©aliste du signal EMG')
    plt.xlabel('Points temporels')
    plt.ylabel('Amplitude EMG')
    plt.legend()
    plt.grid(True)
    plt.savefig('emg_future_realistic_forecast.png')

    # Analyse suppl√©mentaire: comparer la distribution statistique
    plt.figure(figsize=(12, 5))

    # Configurer la grille pour deux graphiques c√¥te √† c√¥te
    plt.subplot(1, 2, 1)
    plt.hist(real_history, bins=20, alpha=0.7, label='Donn√©es r√©elles')
    plt.hist(future_predictions, bins=20, alpha=0.7, label='Pr√©dictions')
    plt.title('Distribution des valeurs')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.hist(np.diff(real_history), bins=20, alpha=0.7, label='Diff√©rences r√©elles')
    plt.hist(np.diff(future_predictions), bins=20, alpha=0.7, label='Diff√©rences pr√©dites')
    plt.title('Distribution des variations point-√†-point')
    plt.legend()

    plt.tight_layout()
    plt.savefig('emg_distribution_comparison.png')

.. image:: _static/images/emg_future_realistic_forecast.png
     :alt: emg_future_realistic_forecast 
     :width: 500px
Section 13: Sauvegarder les resultats dans un fichier CSV
------------------------------------------------------------

.. code-block:: python
   # Sauvegarder les pr√©dictions et les vraies valeurs dans un DataFrame
   results_df = pd.DataFrame({
    'y_true': y_test_inv,
    'y_pred': y_pred_inv
   })

  # Sauvegarder dans un fichier CSV
   results_df.to_csv('emg_predictions.csv', index=False)

====================================================================
Ou bien vous pouvez telecharger le model deja entrainer via le lien üëâ [T√©l√©charger le mod√®le (.keras)](https://drive.google.com/file/d/1WQmU3ywLMbfQma6Q_eG_GXgkme735jtM/view?usp=sharing)
====================================================================

5. Pr√©diction du signal EEG
--------------------------

Pour r√©aliser une pr√©diction efficace des signaux EEG, suivez la m√™me structure m√©thodologique que celle √©tablie pour l'EMG, en adaptant simplement les param√®tres aux sp√©cificit√©s des ondes c√©r√©brales:

Section 1: Configuration et importation des biblioth√®ques
Section 2: Pr√©paration des donn√©es
Section 3: Fonction d'extraction de caract√©ristiques
Section 4: Cr√©ation de s√©quences enrichies
Section 5: Division des donn√©es
Section 6: Cr√©ation du mod√®le avanc√©
Section 7: Entra√Ænement du mod√®le
Section 8: Visualisation de l'apprentissage
Section 9: √âvaluation du mod√®le
Section 10: Fonction de pr√©vision r√©aliste
Section 11: Visualisation des motifs r√©els
Section 12: G√©n√©ration et visualisation des pr√©visions futures
section 13: Enregistrement Du predictions dans un csv

.. image:: _static/images/Comparaison.png
     :alt: Comparaison entre les valeures reels et predits  
     :width: 500px

.. image:: _static/images/Forcast.png
     :alt: Forcasting EEG  
     :width: 500px
6. Creation d;une Dataframe des predictions 
--------------------------

.. code-block:: python

  # Charger les fichiers CSV
    df1 = pd.read_csv(fichier1)
    df2 = pd.read_csv(fichier2)
    df = pd.concat([df1, df2], ignore_index=True)

====================================================================
Ou bien vous pouvez telecharger le model deja entrainee via le lien üëâ [T√©l√©charger le mod√®le (.keras)](https://drive.google.com/file/d/1ZKH9WgfoknVqFe2q4FvL_zb96o9EVRid/view?usp=sharing)
====================================================================
6. D√©tection des troubles du sommeil
-----------------------------------

Cette section finale combine les analyses des signaux EEG et EMG pour identifier les troubles du sommeil.

Structure du Package
===================

Le package est divis√© en plusieurs modules:

1. **signal_processing.py**: Fonctions de base pour le traitement du signal
2. **apnea_detection.py**: Algorithmes pour la d√©tection d'apn√©e du sommeil
3. **insomnia_detection.py**: Algorithmes pour la d√©tection d'insomnie
4. **analysis_utils.py**: Utilitaires d'analyse et fonctions communes
5. **main.py**: Point d'entr√©e principal pour l'application

Module: signal_processing.py
===========================

Ce module contient les fonctions fondamentales pour le traitement des signaux EEG et EMG.

.. code-block:: python

    import numpy as np
    from scipy.signal import butter, filtfilt

    def bandpass_filter(signal, lowcut, highcut, fs):
        nyquist = 0.5 * fs
        low = lowcut / nyquist
        high = highcut / nyquist
        
        # Ensure filter frequencies are within valid range
        low = max(0.001, min(low, 0.999))
        high = max(low + 0.001, min(high, 0.999))
        
        b, a = butter(4, [low, high], btype='band')
        return filtfilt(b, a, signal)

Module: apnea_detection.py
=========================

Ce module impl√©mente les algorithmes pour d√©tecter l'apn√©e du sommeil √† partir des signaux EEG et EMG.

.. code-block:: python

    import numpy as np
    import pandas as pd
    from scipy.signal import welch
    from signal_processing import bandpass_filter

    def detect_apnea(eeg, emg, fs):
        
        # Handle potential NaN values
        eeg = np.nan_to_num(eeg)
        emg = np.nan_to_num(emg)
        
        # Filtrage
        eeg_filtered = bandpass_filter(eeg, 0.5, 45, fs)
        emg_filtered = bandpass_filter(emg, 10, 100, fs)
        
        # Analyse spectrale EEG (bande alpha : 8‚Äì13 Hz)
        f_eeg, pxx_eeg = welch(eeg_filtered, fs=fs, nperseg=fs*2)
        alpha_indices = np.where((f_eeg >= 8) & (f_eeg <= 13))
        alpha_power = np.sum(pxx_eeg[alpha_indices])
        
        # Normaliser la puissance alpha par rapport √† la puissance totale
        total_power = np.sum(pxx_eeg)
        normalized_alpha = alpha_power / total_power if total_power > 0 else 0
        
        # Analyse EMG : RMS (amplitude musculaire)
        emg_rms = np.sqrt(np.mean(emg_filtered ** 2))
        
        # Calculer des seuils adaptatifs bas√©s sur les donn√©es
        alpha_threshold = 0.3  # Proportion relative de la puissance alpha
        emg_threshold = np.percentile(emg_filtered, 25)  # 25√®me percentile comme seuil bas
        
        # Ajout d'une d√©tection de variation d'EMG (indicateur de micro-√©veil)
        emg_variance = np.var(emg_filtered)
        
        # Heuristiques:
        result = {
            "alpha_power": normalized_alpha,
            "emg_rms": emg_rms,
            "emg_variance": emg_variance
        }
        
        if normalized_alpha > alpha_threshold and emg_rms < emg_threshold and emg_variance > 0.01:
            result["diagnosis"] = "Apn√©e"
        else:
            result["diagnosis"] = "No Apn√©e"
        
        return result

    def analyze_signal_windows_apnea(df, fs=100, window_size=30):
      
        # Copier le dataframe pour ne pas modifier l'original
        result_df = df.copy()
        
        # Calculer le nombre d'√©chantillons par fen√™tre
        samples_per_window = fs * window_size
        
        # Nombre total d'√©chantillons
        total_samples = len(df)
        
        # Cr√©er des colonnes pour les r√©sultats
        result_df['Apnee_Status'] = "Non analys√©"
        result_df['Alpha_Power'] = np.nan
        result_df['EMG_RMS'] = np.nan
        result_df['EMG_Variance'] = np.nan
        
        # Si le dataset est trop petit pour l'analyse par fen√™tres
        if total_samples < samples_per_window:
            # Analyser l'ensemble du dataset comme une seule fen√™tre
            eeg_data = df['EEG'].values
            emg_data = df['EMG'].values
            
            # D√©tection d'apn√©e
            result = detect_apnea(eeg_data, emg_data, fs)
            
            # Remplir toutes les lignes avec le m√™me r√©sultat
            result_df['Apnee_Status'] = result['diagnosis']
            result_df['Alpha_Power'] = result['alpha_power']
            result_df['EMG_RMS'] = result['emg_rms']
            result_df['EMG_Variance'] = result['emg_variance']
        else:
            # Traiter par fen√™tres
            for start_idx in range(0, total_samples, samples_per_window):
                end_idx = min(start_idx + samples_per_window, total_samples)
                
                # Extraire les donn√©es de la fen√™tre
                eeg_window = df['EEG'].iloc[start_idx:end_idx].values
                emg_window = df['EMG'].iloc[start_idx:end_idx].values
                
                # V√©rifier si la fen√™tre est assez grande pour l'analyse
                if len(eeg_window) < fs:  # Fen√™tre trop petite
                    continue
                    
                # Analyser la fen√™tre
                result = detect_apnea(eeg_window, emg_window, fs)
                
                # Ajouter les r√©sultats au DataFrame
                result_df.loc[start_idx:end_idx-1, 'Apnee_Status'] = result['diagnosis']
                result_df.loc[start_idx:end_idx-1, 'Alpha_Power'] = result['alpha_power']
                result_df.loc[start_idx:end_idx-1, 'EMG_RMS'] = result['emg_rms']
                result_df.loc[start_idx:end_idx-1, 'EMG_Variance'] = result['emg_variance']
        
        return result_df

Module: insomnia_detection.py
===========================

Ce module fournit des algorithmes pour la d√©tection d'insomnie √† partir des signaux EEG et EMG.

.. code-block:: python

    import numpy as np
    import pandas as pd
    from scipy.signal import welch
    from signal_processing import bandpass_filter

    def detect_insomnia(eeg, emg, fs):
  
        # Nettoyage des donn√©es
        eeg = np.nan_to_num(eeg)
        emg = np.nan_to_num(emg)
        
        # Filtrage des signaux
        eeg_filtered = bandpass_filter(eeg, 0.5, 45, fs)
        emg_filtered = bandpass_filter(emg, 10, 100, fs)
        
        # Analyse spectrale EEG 
        f_eeg, pxx_eeg = welch(eeg_filtered, fs=fs, nperseg=fs*2)
        
        # Extraire diff√©rentes bandes de fr√©quence
        delta_indices = np.where((f_eeg >= 0.5) & (f_eeg <= 4))
        theta_indices = np.where((f_eeg >= 4) & (f_eeg <= 8))
        alpha_indices = np.where((f_eeg >= 8) & (f_eeg <= 13))
        beta_indices = np.where((f_eeg >= 15) & (f_eeg <= 30))
        
        # Calculer la puissance dans chaque bande
        delta_power = np.sum(pxx_eeg[delta_indices])
        theta_power = np.sum(pxx_eeg[theta_indices])
        alpha_power = np.sum(pxx_eeg[alpha_indices])
        beta_power = np.sum(pxx_eeg[beta_indices])
        
        # Calculer les ratios significatifs
        total_power = np.sum(pxx_eeg)
        normalized_beta = beta_power / total_power if total_power > 0 else 0
        beta_delta_ratio = beta_power / delta_power if delta_power > 0 else 999  # Valeur √©lev√©e si pas de delta (√©veil)
        
        # Analyse EMG (tension musculaire)
        emg_rms = np.sqrt(np.mean(emg_filtered ** 2))  # Niveau global d'activit√© musculaire
        emg_variance = np.var(emg_filtered)  # Variabilit√© (micro-√©veils)
        
        # D√©tection des micro-√©veils bas√©e sur des pics d'EMG
        # Calculer la variation rapide de l'EMG (diff√©rence d'un √©chantillon √† l'autre)
        emg_diff = np.diff(emg_filtered)
        emg_diff = np.append(emg_diff, 0)  # Ajouter un z√©ro pour conserver la m√™me longueur
        micro_arousal_count = np.sum(np.abs(emg_diff) > 3 * np.std(emg_diff))  # Nombre de changements brusques
        
        # Normaliser le nombre de micro-√©veils par dur√©e (par minute)
        micro_arousal_per_min = micro_arousal_count / (len(emg) / fs / 60)
        
        # Seuils - √† ajuster selon les donn√©es cliniques
        beta_threshold = 0.25  # Proportion relativement √©lev√©e de b√™ta
        beta_delta_threshold = 1.5  # Plus de b√™ta que de delta = √©veil/insomnie
        emg_threshold = np.percentile(emg_filtered, 60)  # Tension musculaire au-dessus de la m√©diane
        micro_arousal_threshold = 3  # Plus de 3 micro-√©veils par minute
        
        # Calculer un score d'insomnie bas√© sur ces facteurs
        insomnia_score = 0
        if normalized_beta > beta_threshold:
            insomnia_score += 1
        if beta_delta_ratio > beta_delta_threshold:
            insomnia_score += 1
        if emg_rms > emg_threshold:
            insomnia_score += 1
        if micro_arousal_per_min > micro_arousal_threshold:
            insomnia_score += 1
        
        # Classification bas√©e sur le score
        if insomnia_score >= 3:
            diagnosis = "Insomnie s√©v√®re"
        elif insomnia_score == 2:
            diagnosis = "Insomnie mod√©r√©e"
        elif insomnia_score == 1:
            diagnosis = "Insomnie l√©g√®re"
        else:
            diagnosis = "Normal"
        
        # R√©sultats d√©taill√©s
        result = {
            "diagnosis": diagnosis,
            "insomnia_score": insomnia_score,
            "beta_power": normalized_beta,
            "beta_delta_ratio": beta_delta_ratio,
            "emg_rms": emg_rms,
            "micro_arousal_per_min": micro_arousal_per_min
        }
        
        return result

    def analyze_signal_windows_insomnia(df, fs=100, window_size=30):
        
        # Copier le dataframe pour ne pas modifier l'original
        result_df = df.copy()
        
        # Calculer le nombre d'√©chantillons par fen√™tre
        samples_per_window = fs * window_size
        
        # Nombre total d'√©chantillons
        total_samples = len(df)
        
        # Cr√©er des colonnes pour les r√©sultats
        result_df['Insomnie_Status'] = "Non analys√©"
        result_df['Insomnie_Score'] = np.nan
        result_df['Beta_Power'] = np.nan
        result_df['Beta_Delta_Ratio'] = np.nan
        result_df['EMG_Tension'] = np.nan
        result_df['Micro_Arousals'] = np.nan
        
        # Si le dataset est trop petit pour l'analyse par fen√™tres
        if total_samples < samples_per_window:
            # Analyser l'ensemble du dataset comme une seule fen√™tre
            eeg_data = df['EEG'].values
            emg_data = df['EMG'].values
            
            # D√©tection d'insomnie
            result = detect_insomnia(eeg_data, emg_data, fs)
            
            # Remplir toutes les lignes avec le m√™me r√©sultat
            result_df['Insomnie_Status'] = result['diagnosis']
            result_df['Insomnie_Score'] = result['insomnia_score']
            result_df['Beta_Power'] = result['beta_power']
            result_df['Beta_Delta_Ratio'] = result['beta_delta_ratio']
            result_df['EMG_Tension'] = result['emg_rms']
            result_df['Micro_Arousals'] = result['micro_arousal_per_min']
        else:
            # Traiter par fen√™tres
            for start_idx in range(0, total_samples, samples_per_window):
                end_idx = min(start_idx + samples_per_window, total_samples)
                
                # Extraire les donn√©es de la fen√™tre
                eeg_window = df['EEG'].iloc[start_idx:end_idx].values
                emg_window = df['EMG'].iloc[start_idx:end_idx].values
                
                # V√©rifier si la fen√™tre est assez grande pour l'analyse
                if len(eeg_window) < fs:  # Fen√™tre trop petite
                    continue
                    
                # Analyser la fen√™tre
                result = detect_insomnia(eeg_window, emg_window, fs)
                
                # Ajouter les r√©sultats au DataFrame
                result_df.loc[start_idx:end_idx-1, 'Insomnie_Status'] = result['diagnosis']
                result_df.loc[start_idx:end_idx-1, 'Insomnie_Score'] = result['insomnia_score']
                result_df.loc[start_idx:end_idx-1, 'Beta_Power'] = result['beta_power']
                result_df.loc[start_idx:end_idx-1, 'Beta_Delta_Ratio'] = result['beta_delta_ratio']
                result_df.loc[start_idx:end_idx-1, 'EMG_Tension'] = result['emg_rms']
                result_df.loc[start_idx:end_idx-1, 'Micro_Arousals'] = result['micro_arousal_per_min']
        
        return result_df

Module: analysis_utils.py
========================

Ce module fournit des utilitaires pour l'analyse et la sauvegarde des r√©sultats.

.. code-block:: python

    import pandas as pd
    import numpy as np
    import os
    from apnea_detection import analyze_signal_windows_apnea
    from insomnia_detection import analyze_signal_windows_insomnia

    def analyze_and_save_results(input_dataframe=None, input_file=None, output_file="resultats_analyse_sommeil.csv", fs=100):
        
        try:
            # Charger les donn√©es si un dataframe n'est pas fourni directement
            if input_dataframe is None:
                if input_file is not None:
                    print(f"Chargement des donn√©es depuis {input_file}")
                    df = pd.read_csv(input_file)
                else:
                    raise ValueError("Vous devez fournir soit un DataFrame, soit un chemin vers un fichier CSV")
            else:
                df = input_dataframe
            
            # V√©rifier la pr√©sence des colonnes requises
            required_columns = ['EEG', 'EMG']
            for col in required_columns:
                if col not in df.columns:
                    raise ValueError(f"La colonne {col} est requise mais n'a pas √©t√© trouv√©e dans les donn√©es")
            
            print("Analyse des donn√©es pour la d√©tection d'apn√©e...")
            # Fen√™tre de 5 secondes pour l'apn√©e
            df_apnee = analyze_signal_windows_apnea(df, fs=fs, window_size=5)
            
            print("Analyse des donn√©es pour la d√©tection d'insomnie...")
            # Fen√™tre de 30 secondes pour l'insomnie (standard en polysomnographie)
            df_final = analyze_signal_windows_insomnia(df_apnee, fs=fs, window_size=30)
            
            # Calculer des statistiques globales
            apnee_count = (df_final['Apnee_Status'] == 'Apn√©e').sum()
            normal_apnee_count = (df_final['Apnee_Status'] == 'No Apn√©e').sum()
            
            severe_insomnia = (df_final['Insomnie_Status'] == 'Insomnie s√©v√®re').sum()
            moderate_insomnia = (df_final['Insomnie_Status'] == 'Insomnie mod√©r√©e').sum()
            mild_insomnia = (df_final['Insomnie_Status'] == 'Insomnie l√©g√®re').sum()
            normal_insomnia = (df_final['Insomnie_Status'] == 'Normal').sum()
            
            total_samples = len(df_final)
            
            # Afficher un r√©sum√©
            print("\n===== R√âSUM√â DE L'ANALYSE =====")
            print(f"Nombre total d'√©chantillons: {total_samples}")
            
            print("\nR√©sultats Apn√©e:")
            print(f"- Apn√©e d√©tect√©e: {apnee_count} √©chantillons ({apnee_count/total_samples*100:.1f}%)")
            print(f"- Normal: {normal_apnee_count} √©chantillons ({normal_apnee_count/total_samples*100:.1f}%)")
            
            print("\nR√©sultats Insomnie:")
            print(f"- Insomnie s√©v√®re: {severe_insomnia} √©chantillons ({severe_insomnia/total_samples*100:.1f}%)")
            print(f"- Insomnie mod√©r√©e: {moderate_insomnia} √©chantillons ({moderate_insomnia/total_samples*100:.1f}%)")
            print(f"- Insomnie l√©g√®re: {mild_insomnia} √©chantillons ({mild_insomnia/total_samples*100:.1f}%)")
            print(f"- Normal: {normal_insomnia} √©chantillons ({normal_insomnia/total_samples*100:.1f}%)")
            
            # Sauvegarder les r√©sultats
            print(f"\nSauvegarde des r√©sultats dans {output_file}")
            df_final.to_csv(output_file, index=False)
            print(f"Sauvegarde termin√©e avec succ√®s!")
            
            return df_final
            
        except Exception as e:
            print(f"ERREUR: {str(e)}")
            return None

Module: main.py
=============

Ce module est le point d'entr√©e principal de l'application.

.. code-block:: python

    import os
    import pandas as pd
    from analysis_utils import analyze_and_save_results

    def main():
        
        try:
            # V√©rifier si dfapne existe dans l'environnement actuel
            try:
                print("Utilisation du DataFrame 'dfapne' existant")
                results = analyze_and_save_results(input_dataframe=df)
            except NameError:
                # Si dfapne n'existe pas, demander √† l'utilisateur de fournir un fichier
                print("Le DataFrame 'df' n'a pas √©t√© trouv√©")
                
                # Demander √† l'utilisateur le chemin du fichier
                input_file = input("Entrez le chemin vers votre fichier CSV (avec les colonnes EEG et EMG): ")
                output_file = input("Entrez le chemin pour la sauvegarde des r√©sultats (ou laissez vide pour 'resultats_analyse_sommeil.csv'): ")
                
                if not output_file:
                    output_file = "resultats_analyse_sommeil.csv"
                    
                if os.path.exists(input_file):
                    results = analyze_and_save_results(input_file=input_file, output_file=output_file)
                else:
                    print(f"ERREUR: Le fichier {input_file} n'existe pas")
                    
        except Exception as e:
            print(f"ERREUR CRITIQUE: {str(e)}")

    if __name__ == "__main__":
        main()

Installation et Utilisation
=========================

1. Installation des d√©pendances
------------------------------

.. code-block:: bash

    pip install numpy pandas scipy matplotlib

2. Structure des fichiers
-----------------------

Organisez vos fichiers comme suit:

.. code-block:: text

    sleep_analysis/
    ‚îú‚îÄ‚îÄ signal_processing.py
    ‚îú‚îÄ‚îÄ apnea_detection.py
    ‚îú‚îÄ‚îÄ insomnia_detection.py
    ‚îú‚îÄ‚îÄ analysis_utils.py
    ‚îî‚îÄ‚îÄ main.py

3. Lancement de l'analyse
------------------------

Pour analyser des donn√©es de sommeil:

.. code-block:: bash

    python main.py

L'application vous demandera de sp√©cifier le chemin vers votre fichier CSV contenant les donn√©es EEG et EMG.

4. Format d'entr√©e attendu
-------------------------

Le fichier CSV d'entr√©e doit contenir au moins deux colonnes:
- 'EEG': Signal √©lectroenc√©phalographique
- 'EMG': Signal √©lectromyographique

Exemple:

.. code-block:: text

    EEG,EMG
    120.3,30.2
    125.7,31.5
    ...

5. Interpr√©tation des r√©sultats
-----------------------------

Le fichier de sortie contiendra les colonnes suivantes:
- Colonnes originales (EEG, EMG)
- Apnee_Status: 'Apn√©e' ou 'No Apn√©e'
- Alpha_Power: Puissance relative des ondes alpha
- EMG_RMS: Amplitude moyenne de l'EMG
- EMG_Variance: Variation du signal EMG
- Insomnie_Status: 'Insomnie s√©v√®re', 'Insomnie mod√©r√©e', 'Insomnie l√©g√®re' ou 'Normal'
- Insomnie_Score: Score num√©rique (0-4) d'insomnie
- Beta_Power: Puissance relative des ondes b√™ta
- Beta_Delta_Ratio: Ratio entre ondes b√™ta et delta
- EMG_Tension: Niveau de tension musculaire
- Micro_Arousals: Micro-√©veils par minute

Fondements scientifiques
======================

La d√©tection d'apn√©e du sommeil s'appuie sur plusieurs marqueurs physiologiques:
- Augmentation de l'activit√© des ondes alpha (8-13 Hz) pendant les √©pisodes d'apn√©e
- Diminution du tonus musculaire (EMG)
- Fluctuations soudaines du signal EMG indiquant des micro-√©veils

Pour l'insomnie, les marqueurs cl√©s incluent:
- Augmentation de l'activit√© des ondes b√™ta (15-30 Hz)
- Ratio √©lev√© entre les ondes b√™ta et delta
- Tonus musculaire (EMG) √©lev√©
- Fr√©quence accrue de micro-√©veils

Limitations
==========

- L'analyse automatis√©e ne remplace pas un diagnostic clinique par un m√©decin.
- Les seuils utilis√©s sont bas√©s sur la litt√©rature mais pourraient n√©cessiter un ajustement pour des populations sp√©cifiques.
- La qualit√© des signaux d'entr√©e affecte significativement la pr√©cision des r√©sultats.
- L'absence d'autres signaux polysomnographiques (ECG, flux respiratoire, etc.) peut limiter la pr√©cision de la d√©tection d'apn√©e.

R√©f√©rences
=========

1. Berry, R. B., et al. (2012). The AASM manual for the scoring of sleep and associated events: Rules, terminology and technical specifications. Version 2.0. Darien, IL: American Academy of Sleep Medicine.
2. Iber, C., et al. (2007). The AASM manual for the scoring of sleep and associated events: Rules, terminology and technical specifications. Westchester, IL: American Academy of Sleep Medicine.
3. Morin, C. M., & Benca, R. (2012). Chronic insomnia. The Lancet, 379(9821), 1129-1141.


Conseils d'optimisation
======================

Pour obtenir les meilleurs r√©sultats :

1. *Qualit√© des donn√©es* :

   - Utilisez des enregistrements PSG complets (8h minimum)
   - V√©rifiez que les signaux EEG et EMG sont clairement identifi√©s
   - Pr√©f√©rez les fichiers `.edf` standardis√©s (ex : Sleep-EDF database)

2. *Ajustement des param√®tres du mod√®le* :

   - Augmentez le nombre d'√©poques pour un meilleur apprentissage
   - Testez diff√©rentes architectures LSTM (couches, unit√©s)
   - Variez la taille des s√©quences d'entr√©e

3. *Adaptation des seuils de d√©tection* :

   - Ajustez les seuils selon la sensibilit√© souhait√©e
   - Pour un d√©pistage large : r√©duisez les seuils
   - Pour minimiser les faux positifs : augmentez les seuils

D√©pannage
========

Probl√®mes courants et solutions
------------------------------

1. **Erreur lors du chargement du fichier `.edf`** :

   - *Probl√®me*: MNE ne peut pas lire certains canaux
   - *Solution*: V√©rifiez les noms des canaux avec `raw.ch_names` et ajustez le code

2. *Erreurs de pr√©diction* :

   - *Probl√®me*: Mod√®le peu performant (MSE √©lev√©)
   - *Solution*: Augmentez les donn√©es d'entra√Ænement ou essayez d'autres architectures de mod√®le

3. *M√©moire insuffisante* :

   - *Probl√®me*: Erreur de m√©moire lors du traitement des grands fichiers
   - *Solution*: R√©duisez la taille des batchs ou sous-√©chantillonnez les donn√©es

4. *Format de donn√©es incompatible* :

   - *Probl√®me*: Structure de fichier EDF non standard
   - *Solution*: Utilisez des outils de conversion comme EDFbrowser avant l'importation

Ressources suppl√©mentaires
=========================

- Sleep-EDF Database: https://physionet.org/content/sleep-edfx/1.0.0/
- Documentation MNE-Python: https://mne.tools/stable/index.html
- Tutoriel d'analyse du sommeil avec Python: https://raphaelvallat.com/yasa/build/html/index.html

Support
======

Si vous rencontrez des probl√®mes avec le notebook :

- Consultez les forums Kaggle pour des solutions similaires
