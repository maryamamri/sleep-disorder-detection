===================
Guide d'utilisation
===================

Projet de d√©tection des troubles du sommeil bas√© sur l'analyse de PSG
====================================================================

Ce guide d√©taill√© explique comment utiliser le projet de d√©tection des troubles du sommeil √† partir de donn√©es polysomnographiques (PSG) au format `.edf`. Le syst√®me analyse les signaux physiologiques pour identifier trois troubles principaux : l'insomnie, l'apn√©e du sommeil et la narcolepsie.

Pr√©requis
=========

Avant de commencer, assurez-vous d'avoir :

- Un compte Kaggle avec acc√®s aux notebooks
- Connaissance de base de Python et des notebooks Jupyter
- Un fichier PSG au format `.edf` (par exemple de la base de donn√©es Sleep-EDF)

Utilisation du notebook Kaggle
=============================

Le projet est enti√®rement impl√©ment√© dans un notebook Kaggle. Pour l'utiliser :

1. Acc√©dez au notebook via le lien fourni ou copiez-le dans votre espace Kaggle
2. T√©l√©chargez votre fichier `.edf` dans l'espace de donn√©es Kaggle
3. Ex√©cutez les cellules du notebook dans l'ordre

Structure du notebook
===================

Le notebook est organis√© en sections correspondant aux diff√©rentes √©tapes du pipeline de traitement :

::

    1. Configuration et importation des biblioth√®ques
    2. Chargement des fichiers .edf
    3. Transformation des signaux en CSV
    4. Pr√©traitement des donn√©es
    5. Pr√©diction des signaux (EEG et EMG)
    6. D√©tection des troubles du sommeil
    7. Visualisation des r√©sultats

√âtapes d√©taill√©es du pipeline
============================

1. Importation du fichier `.edf`
----------------------------------

Dans cette section du notebook, vous importez votre fichier PSG au format `.edf`.

*Code √† ex√©cuter dans le notebook* :

python

    import mne
    import os
    
    # Sp√©cifiez le chemin vers votre fichier .edf
    edf_file = '../input/sleep-edf-database-expanded/SC4001E0-PSG.edf'
    
    # Chargement du fichier EDF
    raw = mne.io.read_raw_edf(edf_file, preload=True)
    
    # Affichage des informations sur les canaux disponibles
    print(raw.info)
    
    # Liste des canaux disponibles
    print("Canaux disponibles:", raw.ch_names)

**R√©sultat attendu** :
- Affichage des canaux disponibles dans le fichier EDF
- Confirmation que les signaux EEG (Fpz-Cz), EMG et EOG sont pr√©sents
- Affichage des caract√©ristiques des signaux (fr√©quence d'√©chantillonnage, etc.)

**Conseils** :
- V√©rifiez que les canaux EEG, EMG et EOG sont correctement identifi√©s
- Assurez-vous que la fr√©quence d'√©chantillonnage est suffisante (g√©n√©ralement 100 Hz)

2. Transformation en CSV
-----------------------

Cette section du notebook convertit les signaux bruts du fichier ``.edf`` en DataFrames pandas pour faciliter l'analyse.

**Code √† ex√©cuter** :

python

    import pandas as pd
    import numpy as np

    # Extraire les signaux en DataFrames
    eeg_data = raw.get_data(picks=['EEG Fpz-Cz'])
    emg_data = raw.get_data(picks=['EMG submental'])
    eog_data = raw.get_data(picks=['EOG horizontal'])

    # Cr√©er des DataFrames pandas
    sampling_freq = raw.info['sfreq']
    times = np.arange(0, len(eeg_data[0])) / sampling_freq

    eeg_df = pd.DataFrame({
    'timestamp': times,
    'value': eeg_data[0],
    'channel': 'EEG Fpz-Cz'
    })

    emg_df = pd.DataFrame({
    'timestamp': times,
    'value': emg_data[0],
    'channel': 'EMG submental'
    })

    eog_df = pd.DataFrame({
    'timestamp': times,
    'value': eog_data[0],
    'channel': 'EOG horizontal'
    })

   # Sauvegarder en CSV si n√©cessaire (optionnel dans Kaggle)
   eeg_df.to_csv('eeg.csv', index=False)
   emg_df.to_csv('emg.csv', index=False)
   eog_df.to_csv('eog.csv', index=False)

   # Afficher les premi√®res lignes pour v√©rification
   print("Donn√©es EEG:")
   print(eeg_df.head())

   # Fusionner tous les signaux dans une seule DataFrame
  dftotal = pd.concat([eeg_df, emg_df, eog_df], ignore_index=True)

  # Afficher les premi√®res lignes de la DataFrame fusionn√©e
  print("\nDonn√©es fusionn√©es (dftotal):")
  print(dftotal.head())

  # Sauvegarder la DataFrame fusionn√©e en CSV si n√©cessaire
  dftotal.to_csv('all_signals.csv', index=False)

*R√©sultat attendu* :
- Cr√©ation de trois DataFrames contenant les signaux EEG, EMG et EOG
- Structure des DataFrames avec colonnes : timestamp, value, channel
- Affichage des premi√®res lignes de donn√©es pour v√©rification
- Creation d'une dataframe dftotal qui contient tous les signaux
3. Pr√©traitement des donn√©es
---------------------------

Cette section du notebook nettoie et pr√©pare les donn√©es pour l'analyse.

*Code √† ex√©cuter* :

.. code-block:: python
    import statsmodels.api as sm
    import pandas as pd
    from sklearn.preprocessing import MinMaxScaler
    import matplotlib.pyplot as plt
    dftotal.isna().sum()
    dftotal.dropna(inplace=True)
    
    sm.qqplot(dftotal.Label, line='s')
    sm.qqplot(dftotal["EEG Fpz-Cz"], line='s')

    # Supposons que votre DataFrame est dftotal
    colonnes_signaux = ['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'EMG submental']

    # Initialiser le MinMaxScaler (par d√©faut, mise √† l'√©chelle entre 0 et 1)
    scaler = MinMaxScaler()

    # Appliquer la normalisation aux colonnes s√©lectionn√©es
    dftotal[colonnes_signaux] = scaler.fit_transform(dftotal[colonnes_signaux])
    
    dftotal['EEG Fpz-Cz'].plot(title="EEG Fpz-Cz	",figsize=(20,5))
    plt.show()
    
    dftotal['EEG Pz-Oz'].plot(title="EEG Pz-Oz",figsize=(20,5))
    plt.show()
  
    dftotal['EOG horizontal'].plot(title="EOG horizontal",figsize=(20,5))
    plt.show() 


*R√©sultat attendu* :
- DataFrames pr√©trait√©s avec :
  - Pas de valeurs manquantes
  - Signal normalis√© 
  - Graphiques montrant les signaux  apr√®s pr√©traitement

4. Pr√©diction du signal EMG
--------------------------

Cette section pr√©sente une approche avanc√©e pour analyser le signal EMG afin de d√©tecter des mouvements anormaux. Le syst√®me utilise des techniques d'apprentissage profond pour mod√©liser les patterns complexes pr√©sents dans les signaux c√©r√©braux.

### Composantes principales

1. *Pr√©traitement des donn√©es*: Normalisation des signaux EEG bruts
2. *Extraction de caract√©ristiques*: Calcul de m√©triques statistiques, fr√©quentielles et de complexit√©
3. *Mod√©lisation hybride*: Combinaison de couches convolutives et LSTM bidirectionnelles
4. *Pr√©diction adaptative*: G√©n√©ration de signaux EEG futurs avec maintien des propri√©t√©s statistiques

### Code d'impl√©mentation

python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Conv1D, MaxPooling1D, Input
from tensorflow.keras.layers import LayerNormalization, GaussianNoise, Concatenate, Add, GlobalAveragePooling1D
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
import seaborn as sns

# Configuration pour am√©liorer les performances
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)

# D√©finir les param√®tres de graines al√©atoires pour la reproductibilit√©
np.random.seed(42)
tf.random.set_seed(42)

# FIX: V√©rifier si dftotal existe, sinon cr√©er des donn√©es synth√©tiques pour test
try:
    eeg_data = dftotal['EMG submental'].values  # Utilisation de vos donn√©es
except NameError:
    print("Variable 'dftotal' not found. Creating synthetic data for testing...")
    # G√©n√©rer des donn√©es EEG synth√©tiques pour test
    n_samples = 3000
    t = np.linspace(0, 30, n_samples)
    eeg_data = np.sin(0.5*t) + 0.2*np.sin(2.5*t) + 0.1*np.sin(7.5*t) + 0.05*np.random.randn(n_samples)

# Param√®tres du mod√®le - optimis√©s pour pr√©server les fluctuations
sequence_length = 30  # Raccourci pour capturer les oscillations √† plus haute fr√©quence
pred_length = 1  # Pr√©dire un point √† la fois
stride = 1  # Augmenter le nombre d'exemples d'entra√Ænement
batch_size = 32  # Petit batch pour meilleur ajustement
epochs = 50  # Plus d'epochs pour un apprentissage plus fin

# Normalisation des donn√©es - StandardScaler peut √™tre pr√©f√©rable pour pr√©server les variations
scaler = MinMaxScaler(feature_range=(0, 1))
eeg_data_scaled = scaler.fit_transform(eeg_data.reshape(-1, 1)).flatten()

# √âchantillonnage des donn√©es
sample_size = min(150000, len(eeg_data_scaled))  # FIX: S'assurer que sample_size n'est pas sup√©rieur √† la taille des donn√©es
eeg_sample = eeg_data_scaled[:sample_size]

# --- FONCTION D'EXTRACTION DE CARACT√âRISTIQUES AM√âLIOR√âE ---
def extract_features(data, seq_length):
    """Extraire des caract√©ristiques avanc√©es du signal EEG"""
    features = []
    
    # FIX: V√©rifier que les donn√©es ont une forme correcte
    if len(data.shape) > 1 and data.shape[0] == 1:
        data = data.flatten()
    
    # FIX: V√©rifier que la s√©quence est assez longue
    if len(data) < seq_length:
        print(f"Warning: Data length {len(data)} is less than sequence length {seq_length}")
        # Padding si n√©cessaire
        if len(data) > 0:
            padding = np.zeros(seq_length - len(data))
            data = np.concatenate([data, padding])
        else:
            # Si data est vide, retourner un tableau vide avec la bonne forme
            return np.zeros((0, 11))
    
    for i in range(len(data) - seq_length + 1):
        segment = data[i:i+seq_length]
        
        # Caract√©ristiques statistiques
        mean = np.mean(segment)
        std = np.std(segment)
        min_val = np.min(segment)
        max_val = np.max(segment)
        range_val = max_val - min_val
        
        # Tendance et variation
        gradient = np.gradient(segment).mean()
        abs_gradient = np.abs(np.gradient(segment)).mean()  # Mesure de la variabilit√© globale
        
        # Analyse fr√©quentielle
        fft_vals = np.abs(np.fft.rfft(segment))
        # FIX: S'assurer que fft_vals a au moins un √©l√©ment avant d'acc√©der √† l'index 1
        if len(fft_vals) > 1:
            dominant_freq_idx = np.argmax(fft_vals[1:]) + 1  # Ignorer DC (indice 0)
            dominant_freq_val = fft_vals[dominant_freq_idx] / len(segment)
        else:
            dominant_freq_val = 0
        
        # Entropie approximative (mesure de la complexit√©/r√©gularit√©)
        # Version simplifi√©e, consid√©rez une impl√©mentation plus compl√®te au besoin
        diffs = np.diff(segment)
        direction_changes = np.sum(np.diff(np.signbit(diffs)) != 0)
        complexity = direction_changes / max(1, (seq_length - 2))  # FIX: √âviter division par z√©ro
        
        # Caract√©ristiques de forme d'onde
        peak_count = len(np.where(np.diff(np.signbit(np.diff(segment))) < 0)[0])  # Nombre de pics
        zero_crossings = len(np.where(np.diff(np.signbit(segment)))[0])  # Nombre de passages √† z√©ro
        
        # Regrouper toutes les caract√©ristiques
        feature_vec = np.array([
            mean, std, min_val, max_val, range_val, 
            gradient, abs_gradient, 
            dominant_freq_val, complexity,
            peak_count / max(1, seq_length), zero_crossings / max(1, seq_length)  # FIX: √âviter division par z√©ro
        ])
        
        features.append(feature_vec)
    
    return np.array(features)

# --- CR√âATION DE S√âQUENCES AVEC CARACT√âRISTIQUES ENRICHIES ---
def create_enriched_sequences(data, seq_length, pred_length=1, stride=1):
    """Cr√©e des s√©quences d'entr√©e/sortie avec des caract√©ristiques enrichies"""
    X_raw, y = [], []
    
    # FIX: V√©rifier que les donn√©es sont suffisantes
    if len(data) <= seq_length + pred_length:
        print(f"Warning: Data length {len(data)} is not sufficient for sequence length {seq_length} and prediction length {pred_length}")
        return np.array([]), np.array([]), np.array([])
    
    for i in range(0, len(data) - seq_length - pred_length + 1, stride):
        X_raw.append(data[i:i + seq_length])
        if pred_length == 1:
            y.append(data[i + seq_length])
        else:
            y.append(data[i + seq_length:i + seq_length + pred_length])
    
    X_raw = np.array(X_raw)
    
    # FIX: V√©rifier que X_raw n'est pas vide avant d'extraire les caract√©ristiques
    if len(X_raw) == 0:
        return np.array([]), np.array([]), np.array([])
    
    # Extraire des caract√©ristiques suppl√©mentaires
    X_features = extract_features(data, seq_length)
    
    # FIX: S'assurer que X_features et X_raw ont le m√™me nombre d'√©chantillons
    min_samples = min(len(X_raw), len(X_features))
    if min_samples == 0:
        return np.array([]), np.array([]), np.array([])
    
    X_raw = X_raw[:min_samples]
    X_features = X_features[:min_samples]
    y = np.array(y)[:min_samples]
    
    return X_raw, X_features, y

# Cr√©er des s√©quences avec caract√©ristiques enrichies
X_raw, X_features, y = create_enriched_sequences(eeg_sample, sequence_length, pred_length, stride)

# FIX: V√©rifier que les donn√©es ne sont pas vides
if len(X_raw) == 0 or len(X_features) == 0 or len(y) == 0:
    raise ValueError("Sequences could not be created. Check your data and parameters.")

X_raw = X_raw.reshape((X_raw.shape[0], X_raw.shape[1], 1))

print(f"Forme des donn√©es brutes: {X_raw.shape}")
print(f"Forme des caract√©ristiques: {X_features.shape}")
print(f"Forme des donn√©es de sortie: {y.shape}")

# Division en ensembles d'entra√Ænement et de test
train_size = int(len(X_raw) * 0.8)
X_raw_train, X_raw_test = X_raw[:train_size], X_raw[train_size:]
X_features_train, X_features_test = X_features[:train_size], X_features[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# FIX: V√©rifier qu'il y a suffisamment de donn√©es pour validation
if train_size < 5:
    raise ValueError(f"Not enough training data. Train size: {train_size}")

# Cr√©ation d'un ensemble de validation
val_size = max(1, int(train_size * 0.2))  # FIX: Au moins 1 √©chantillon pour validation
X_raw_val, X_features_val, y_val = X_raw_train[-val_size:], X_features_train[-val_size:], y_train[-val_size:]
X_raw_train, X_features_train, y_train = X_raw_train[:-val_size], X_features_train[:-val_size], y_train[:-val_size]

# --- MOD√àLE AVANC√â POUR EEG ---
def create_advanced_emg_model(seq_length, feature_dim):
    """
    Mod√®le hybride optimis√© pour capturer la complexit√© des signaux EMG
    """
    # Entr√©e pour la s√©quence brute
    input_seq = Input(shape=(seq_length, 1))
    
    # Entr√©e pour les caract√©ristiques extraites
    input_features = Input(shape=(feature_dim,))
    
    # --- Branche de convolution multi-√©chelle ---
    # Ajouter du bruit subtil pour am√©liorer la g√©n√©ralisation
    x = GaussianNoise(0.005)(input_seq)
    
    # Convolutions parall√®les avec diff√©rentes tailles de noyau pour capturer diff√©rentes √©chelles
    conv_kernels = [2, 3, 5, 7]
    conv_outputs = []
    
    for kernel_size in conv_kernels:
        # FIX: S'assurer que kernel_size n'est pas plus grand que la s√©quence
        if kernel_size <= seq_length:
            conv = Conv1D(
                filters=32, 
                kernel_size=kernel_size,
                padding='same',
                activation='elu'  # ELU peut √™tre meilleur pour pr√©server les variations subtiles
            )(x)
            conv = LayerNormalization()(conv)  # Normalisation pour stabiliser l'entra√Ænement
            conv_outputs.append(conv)
    
    # FIX: V√©rifier qu'il y a des sorties de convolution
    if not conv_outputs:
        raise ValueError(f"All kernel sizes {conv_kernels} are larger than sequence length {seq_length}")
        
    # Concat√©ner les sorties de convolution
    x = Concatenate()(conv_outputs)
    
    # Convolutions dilat√©es pour capturer des d√©pendances √† long terme
    dilation_rates = [1, 2, 4, 8]
    dilated_outputs = []
    
    for dilation_rate in dilation_rates:
        # FIX: V√©rifier que la dilatation n'est pas trop grande pour la s√©quence
        if (3 - 1) * dilation_rate + 1 <= seq_length:  # Taille effective = (kernel_size - 1) * dilation_rate + 1
            dilated_conv = Conv1D(
                filters=32, 
                kernel_size=3, 
                padding='causal', 
                dilation_rate=dilation_rate,
                activation='elu'
            )(x)
            dilated_outputs.append(dilated_conv)
    
    # FIX: V√©rifier qu'il y a des sorties dilat√©es
    if not dilated_outputs:
        # Utiliser une convolution simple si aucune dilatation ne convient
        dilated_conv = Conv1D(
            filters=32, 
            kernel_size=1,  # Kernel size 1 fonctionnera toujours
            activation='elu'
        )(x)
        dilated_outputs.append(dilated_conv)
        
    # Combiner les convolutions dilat√©es
    x = Concatenate()(dilated_outputs)
    x = Conv1D(64, kernel_size=1, activation='elu')(x)  # R√©duction de dimension
    
    # --- Branche LSTM bidirectionnelle ---
    lstm_out = Bidirectional(LSTM(64, return_sequences=True))(x)
    lstm_out = LayerNormalization()(lstm_out)
    lstm_out = Dropout(0.3)(lstm_out)  # Dropout un peu plus √©lev√© pour √©viter le surapprentissage
    lstm_out = Bidirectional(LSTM(48, return_sequences=False))(lstm_out)
    
    # --- Traitement des caract√©ristiques ---
    # Passer les caract√©ristiques par des couches denses pour un meilleur apprentissage
    features_dense = Dense(32, activation='elu')(input_features)
    features_dense = Dense(32, activation='elu')(features_dense)
    
    # --- Fusion des branches ---
    combined = Concatenate()([lstm_out, features_dense])
    
    # Couches de sortie 
    x = Dense(64, activation='elu')(combined)
    x = Dropout(0.2)(x)
    x = Dense(32, activation='elu')(x)
    
    # Couche de sortie - pas d'activation pour la r√©gression
    output = Dense(pred_length)(x)
    
    # Cr√©er le mod√®le
    model = Model(inputs=[input_seq, input_features], outputs=output)
    
    # Optimiseur avec taux d'apprentissage adaptatif et clippage de gradient
    optimizer = Adam(learning_rate=0.001, clipnorm=1.0)
    model.compile(optimizer=optimizer, loss='mse')
    
    return model

# Cr√©er le mod√®le am√©lior√©
model = create_advanced_emg_model(sequence_length, X_features.shape[1])
model.summary()

# Callbacks pour l'entra√Ænement avec sauvegarde et r√©duction du taux d'apprentissage
early_stopping = EarlyStopping(
    monitor='val_loss', 
    patience=15, 
    restore_best_weights=True,
    verbose=1
)
model_checkpoint = ModelCheckpoint(
    'best_emg_model.keras', 
    save_best_only=True, 
    monitor='val_loss',
    verbose=1
)
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss', 
    factor=0.5, 
    patience=6, 
    min_lr=0.00001,
    verbose=1
)

# Entra√Ænement du mod√®le
history = model.fit(
    [X_raw_train, X_features_train], y_train,
    epochs=epochs,
    batch_size=batch_size,
    validation_data=([X_raw_val, X_features_val], y_val),
    callbacks=[early_stopping, model_checkpoint, reduce_lr],
    verbose=1
)

# Visualisation de la courbe d'apprentissage
plt.figure(figsize=(15, 5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('√âvolution de la perte pendant l\'entra√Ænement')
plt.xlabel('√âpoques')
plt.ylabel('Perte (MSE)')
plt.legend()
plt.grid(True)
plt.savefig('emg_training_loss.png')
plt.close()

# FIX: V√©rifier qu'il y a des donn√©es de test avant de pr√©dire
if len(X_raw_test) == 0:
    raise ValueError("No test data available")

# Pr√©diction sur l'ensemble de test
y_pred = model.predict([X_raw_test, X_features_test])

# Inverser la normalisation pour obtenir les valeurs r√©elles
if pred_length == 1:
    y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
    y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()
else:
    y_test_inv = np.array([scaler.inverse_transform(y.reshape(-1, 1)).flatten() for y in y_test])
    y_pred_inv = np.array([scaler.inverse_transform(y.reshape(-1, 1)).flatten() for y in y_pred])

# Calcul de l'erreur
mse = mean_squared_error(y_test_inv, y_pred_inv)
rmse = np.sqrt(mse)
print(f"Erreur quadratique moyenne (MSE): {mse}")
print(f"Racine de l'erreur quadratique moyenne (RMSE): {rmse}")

# --- AM√âLIORATION MAJEURE: PR√âVISION R√âALISTE AVEC RECALCUL DES CARACT√âRISTIQUES ---
def forecast_realistic_emg(model, initial_sequence, steps_ahead=200, scaler=None):
    """
    Pr√©vision r√©aliste de signal EMG qui recalcule les caract√©ristiques √† chaque √©tape
    et utilise une approche adaptative pour maintenir la naturalit√© du signal
    """
    sequence_length = initial_sequence.shape[0]
    future_predictions = []
    
    # S√©quence courante pour la pr√©diction it√©rative
    current_sequence = initial_sequence.flatten().copy()
    
    # FIX: V√©rifier qu'il y a assez de points dans la s√©quence
    if len(current_sequence) < 10:
        print(f"Warning: Initial sequence has only {len(current_sequence)} points, padding with zeros")
        padding = np.zeros(10 - len(current_sequence))
        current_sequence = np.concatenate([current_sequence, padding])
    
    # Historique r√©cent des variations pour maintenir la coh√©rence
    recent_variations = np.diff(current_sequence[-10:])
    variation_history = np.abs(recent_variations).mean()
    
    for i in range(steps_ahead):
        # FIX: V√©rifier que la s√©quence actuelle est de la bonne longueur
        if len(current_sequence) < sequence_length:
            padding = np.zeros(sequence_length - len(current_sequence))
            temp_sequence = np.concatenate([current_sequence, padding])
        else:
            temp_sequence = current_sequence[-sequence_length:]
        
        # Extraire les caract√©ristiques de la s√©quence actuelle
        try:
            # FIX: S'assurer que extract_features re√ßoit un tableau non vide
            if len(temp_sequence) == 0:
                raise ValueError("Empty sequence for feature extraction")
                
            current_features_array = extract_features(temp_sequence, sequence_length)
            
            # FIX: V√©rifier que les caract√©ristiques sont extraites correctement
            if len(current_features_array) == 0:
                raise ValueError("Feature extraction returned empty array")
                
            current_features = current_features_array[0]
        except Exception as e:
            print(f"Error extracting features: {e}")
            # Utiliser des caract√©ristiques par d√©faut
            current_features = np.zeros(X_features.shape[1])
        
        # Pr√©dire le prochain point
        next_point_scaled = model.predict(
            [temp_sequence.reshape(1, sequence_length, 1), 
             current_features.reshape(1, -1)]
        )[0][0]
        
        # Stabilit√© adaptative: si la pr√©diction s'√©carte trop de la tendance r√©cente,
        # appliquer une correction subtile
        last_point = current_sequence[-1]
        max_jump = 2.5 * variation_history  # Limite bas√©e sur la volatilit√© historique
        
        # Limiter les sauts trop grands tout en pr√©servant la direction
        if abs(next_point_scaled - last_point) > max_jump:
            direction = np.sign(next_point_scaled - last_point)
            next_point_scaled = last_point + direction * max_jump
        
        # Ajouter un peu de bruit adaptatif bas√© sur la volatilit√© du signal
        # Plus le signal √©tait volatile, plus on permet de fluctuations
        noise_scale = variation_history * 0.5  # La fluctuation est proportionnelle √† la volatilit√© historique
        # FIX: G√©rer le cas o√π variation_history est 0 ou NaN
        if not np.isfinite(noise_scale) or noise_scale == 0:
            noise_scale = 0.01  # Valeur par d√©faut
            
        noise = np.random.normal(0, noise_scale)
        
        # S'assurer que le bruit ne fait pas sortir la valeur de l'intervalle [0,1]
        next_point_with_noise = np.clip(next_point_scaled + noise, 0, 1)
        
        # Ajouter √† nos pr√©dictions
        future_predictions.append(next_point_with_noise)
        
        # Mettre √† jour la s√©quence pour la prochaine pr√©diction
        current_sequence = np.append(current_sequence[1:], next_point_with_noise)
        
        # Mettre √† jour l'historique des variations pour l'adaptativit√©
        if i >= 1:
            new_variation = abs(future_predictions[-1] - future_predictions[-2])
            # Moyenne mobile exponentielle pour l'historique des variations
            variation_history = 0.85 * variation_history + 0.15 * new_variation
    
    # Convertir les pr√©dictions en array numpy
    future_predictions = np.array(future_predictions)
    
    # Inverser la normalisation si un scaler est fourni
    if scaler is not None:
        future_predictions = scaler.inverse_transform(future_predictions.reshape(-1, 1)).flatten()
    
    return future_predictions

# FIX: V√©rifier qu'il y a des donn√©es de test avant de visualiser
if len(y_test_inv) < 100:
    print("Warning: Not enough test data for visualization. Using available data.")
    visualize_length = min(5, len(y_test_inv))
else:
    visualize_length = 5

# Visualiser quelques exemples de s√©quences r√©elles pour comprendre la variabilit√©
plt.figure(figsize=(15, 5))
for i in range(visualize_length):  # Afficher 5 s√©quences d'exemple (ou moins si pas assez de donn√©es)
    # FIX: S'assurer que l'index est valide
    max_start = max(0, len(y_test_inv) - 100)
    if max_start > 0:
        start_idx = np.random.randint(0, max_start)
        plot_length = min(100, len(y_test_inv) - start_idx)
        plt.plot(y_test_inv[start_idx:start_idx+plot_length], alpha=0.7)
    else:
        # Si pas assez de donn√©es, utiliser tout ce qui est disponible
        plt.plot(y_test_inv, alpha=0.7)

plt.title('Exemples de s√©quences EMG r√©elles (pour comprendre la variabilit√©)')
plt.xlabel('Points temporels')
plt.ylabel('Amplitude EMG')
plt.grid(True)
plt.savefig('emg_real_patterns.png')
plt.close()

# FIX: V√©rifier qu'il y a des donn√©es de test avant de prendre la derni√®re s√©quence
if len(X_raw_test) > 0:
    # Prendre la derni√®re s√©quence comme point de d√©part
    last_known_sequence = X_raw_test[-1]
else:
    # S'il n'y a pas de donn√©es de test, utiliser la derni√®re s√©quence d'entra√Ænement
    last_known_sequence = X_raw_train[-1]

# Pr√©dire les points futurs avec la nouvelle m√©thode r√©aliste
future_steps = 200
future_predictions = forecast_realistic_emg(model, last_known_sequence, future_steps, scaler)

# FIX: V√©rifier qu'il y a assez de donn√©es r√©elles pour la visualisation
if len(y_test_inv) < 100:
    real_history_length = len(y_test_inv)
    print(f"Warning: Only {real_history_length} real data points available for visualization")
else:
    real_history_length = 100

# Visualiser les pr√©dictions futures r√©alistes
plt.figure(figsize=(15, 6))

# Afficher les derni√®res valeurs r√©elles disponibles
real_history = y_test_inv[-real_history_length:]
plt.plot(range(real_history_length), real_history, label='Donn√©es EMG r√©elles', color='blue')

# Afficher les pr√©dictions futures
plt.plot(range(real_history_length-1, real_history_length-1+future_steps), future_predictions, 
         label='Pr√©dictions futures', color='red', linestyle='--')
plt.axvline(x=real_history_length-1, color='green', linestyle='-', label='Pr√©sent')

plt.title('Pr√©vision future r√©aliste du signal EMG')
plt.xlabel('Points temporels')
plt.ylabel('Amplitude EMG')
plt.legend()
plt.grid(True)
plt.savefig('emg_future_realistic_forecast.png')

# Analyse suppl√©mentaire: comparer la distribution statistique
plt.figure(figsize=(12, 5))

# Configurer la grille pour deux graphiques c√¥te √† c√¥te
plt.subplot(1, 2, 1)
plt.hist(real_history, bins=20, alpha=0.7, label='Donn√©es r√©elles')
plt.hist(future_predictions, bins=20, alpha=0.7, label='Pr√©dictions')
plt.title('Distribution des valeurs')
plt.legend()

plt.subplot(1, 2, 2)
plt.hist(np.diff(real_history), bins=20, alpha=0.7, label='Diff√©rences r√©elles')
plt.hist(np.diff(future_predictions), bins=20, alpha=0.7, label='Diff√©rences pr√©dites')
plt.title('Distribution des variations point-√†-point')
plt.legend()

plt.tight_layout()
plt.savefig('emg_distribution_comparison.png')

print("Mod√®le de pr√©vision EMG am√©lior√© termin√©. Les graphiques ont √©t√© sauvegard√©s.")
# Sauvegarder les pr√©dictions et les vraies valeurs dans un DataFrame
results_df = pd.DataFrame({
    'y_true': y_test_inv,
    'y_pred': y_pred_inv
})

# Sauvegarder dans un fichier CSV
results_df.to_csv('emg_predictions.csv', index=False)

====================================================================
Ou bien vous pouvez telecharger le model deja entrainer via le lien üëâ [T√©l√©charger le mod√®le (.keras)](https://drive.google.com/file/d/1WQmU3ywLMbfQma6Q_eG_GXgkme735jtM/view?usp=sharing)
====================================================================
### Explication technique des composantes principales

#### 1. Extraction de caract√©ristiques avanc√©es
La fonction extract_features() calcule plusieurs m√©triques importantes sur les segments de signal EEG:

- *Caract√©ristiques statistiques*: moyenne, √©cart-type, minimum, maximum et amplitude du signal
- *Analyse de tendance*: calcul des gradients moyens pour d√©tecter les changements de direction
- *Analyse fr√©quentielle*: transform√©e de Fourier pour identifier les fr√©quences dominantes
- *Mesures de complexit√©*: calcul approximatif de l'entropie et des changements de direction
- *Forme d'onde*: d√©tection des pics et des passages par z√©ro pour caract√©riser l'oscillation

#### 2. Architecture du mod√®le hybride
Le mod√®le neuronal combine plusieurs approches compl√©mentaires:

- *Convolutions multi-√©chelles*: utilisation de noyaux de tailles vari√©es (2, 3, 5, 7) pour capturer diff√©rentes √©chelles temporelles
- *Convolutions dilat√©es*: permet de percevoir des d√©pendances √† long terme avec des taux de dilatation croissants (1, 2, 4, 8)
- *LSTM bidirectionnels*: analyse la s√©quence dans les deux directions temporelles pour mieux comprendre le contexte
- *Fusion multi-modalit√©*: combine les signaux bruts et les caract√©ristiques extraites pour une pr√©diction plus robuste

#### 3. Pr√©diction r√©aliste avec maintien de statistiques
La fonction forecast_realistic_emg() propose une m√©thode avanc√©e pour g√©n√©rer des pr√©dictions futures:

- *Pr√©diction adaptative*: recalcule les caract√©ristiques √† chaque pas de temps pour plus de pr√©cision
- *Stabilit√© statistique*: limite les variations excessives en fonction de l'historique de volatilit√©
- *Bruit coh√©rent*: ajoute un bruit adaptatif pour maintenir la naturalit√© du signal
- *Moyenne mobile exponentielle*: met √† jour dynamiquement l'estimation de la volatilit√©

### R√©sultats et visualisations
Le code g√©n√®re plusieurs visualisations pour √©valuer la qualit√© des pr√©dictions:

1. Courbe d'apprentissage montrant l'√©volution de la perte d'entra√Ænement et de validation
2. √âchantillons de s√©quences EEG r√©elles pour comprendre la variabilit√© naturelle
3. Pr√©diction future avec comparaison aux donn√©es historiques

5. Pr√©diction du signal EEG
--------------------------

Cette section pr√©sente une approche avanc√©e pour analyser le signal EEG afin de d√©tecter des mouvements anormaux. Le syst√®me utilise des techniques d'apprentissage profond pour mod√©liser les patterns complexes pr√©sents dans les signaux c√©r√©braux.

### Composantes principales

1. *Pr√©traitement des donn√©es*: Normalisation des signaux EEG bruts
2. *Extraction de caract√©ristiques*: Calcul de m√©triques statistiques, fr√©quentielles et de complexit√©
3. *Mod√©lisation hybride*: Combinaison de couches convolutives et LSTM bidirectionnelles
4. *Pr√©diction adaptative*: G√©n√©ration de signaux EEG futurs avec maintien des propri√©t√©s statistiques

### Code d'impl√©mentation

python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Conv1D, MaxPooling1D, Input
from tensorflow.keras.layers import LayerNormalization, GaussianNoise, Concatenate, Add, GlobalAveragePooling1D
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
import seaborn as sns

# Configuration pour am√©liorer les performances
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)

# D√©finir les param√®tres de graines al√©atoires pour la reproductibilit√©
np.random.seed(42)
tf.random.set_seed(42)

# FIX: V√©rifier si dftotal existe, sinon cr√©er des donn√©es synth√©tiques pour test
try:
    eeg_data = dftotal['EEG Fpz-Cz'].values  # Utilisation de vos donn√©es
except NameError:
    print("Variable 'dftotal' not found. Creating synthetic data for testing...")
    # G√©n√©rer des donn√©es EEG synth√©tiques pour test
    n_samples = 3000
    t = np.linspace(0, 30, n_samples)
    eeg_data = np.sin(0.5*t) + 0.2*np.sin(2.5*t) + 0.1*np.sin(7.5*t) + 0.05*np.random.randn(n_samples)

# Param√®tres du mod√®le - optimis√©s pour pr√©server les fluctuations
sequence_length = 30  # Raccourci pour capturer les oscillations √† plus haute fr√©quence
pred_length = 1  # Pr√©dire un point √† la fois
stride = 1  # Augmenter le nombre d'exemples d'entra√Ænement
batch_size = 32  # Petit batch pour meilleur ajustement
epochs = 50  # Plus d'epochs pour un apprentissage plus fin

# Normalisation des donn√©es - StandardScaler peut √™tre pr√©f√©rable pour pr√©server les variations
scaler = MinMaxScaler(feature_range=(0, 1))
eeg_data_scaled = scaler.fit_transform(eeg_data.reshape(-1, 1)).flatten()

# √âchantillonnage des donn√©es
sample_size = min(150000, len(eeg_data_scaled))  # FIX: S'assurer que sample_size n'est pas sup√©rieur √† la taille des donn√©es
eeg_sample = eeg_data_scaled[:sample_size]

# --- FONCTION D'EXTRACTION DE CARACT√âRISTIQUES AM√âLIOR√âE ---
def extract_features(data, seq_length):
    """Extraire des caract√©ristiques avanc√©es du signal EEG"""
    features = []
    
    # FIX: V√©rifier que les donn√©es ont une forme correcte
    if len(data.shape) > 1 and data.shape[0] == 1:
        data = data.flatten()
    
    # FIX: V√©rifier que la s√©quence est assez longue
    if len(data) < seq_length:
        print(f"Warning: Data length {len(data)} is less than sequence length {seq_length}")
        # Padding si n√©cessaire
        if len(data) > 0:
            padding = np.zeros(seq_length - len(data))
            data = np.concatenate([data, padding])
        else:
            # Si data est vide, retourner un tableau vide avec la bonne forme
            return np.zeros((0, 11))
    
    for i in range(len(data) - seq_length + 1):
        segment = data[i:i+seq_length]
        
        # Caract√©ristiques statistiques
        mean = np.mean(segment)
        std = np.std(segment)
        min_val = np.min(segment)
        max_val = np.max(segment)
        range_val = max_val - min_val
        
        # Tendance et variation
        gradient = np.gradient(segment).mean()
        abs_gradient = np.abs(np.gradient(segment)).mean()  # Mesure de la variabilit√© globale
        
        # Analyse fr√©quentielle
        fft_vals = np.abs(np.fft.rfft(segment))
        # FIX: S'assurer que fft_vals a au moins un √©l√©ment avant d'acc√©der √† l'index 1
        if len(fft_vals) > 1:
            dominant_freq_idx = np.argmax(fft_vals[1:]) + 1  # Ignorer DC (indice 0)
            dominant_freq_val = fft_vals[dominant_freq_idx] / len(segment)
        else:
            dominant_freq_val = 0
        
        # Entropie approximative (mesure de la complexit√©/r√©gularit√©)
        # Version simplifi√©e, consid√©rez une impl√©mentation plus compl√®te au besoin
        diffs = np.diff(segment)
        direction_changes = np.sum(np.diff(np.signbit(diffs)) != 0)
        complexity = direction_changes / max(1, (seq_length - 2))  # FIX: √âviter division par z√©ro
        
        # Caract√©ristiques de forme d'onde
        peak_count = len(np.where(np.diff(np.signbit(np.diff(segment))) < 0)[0])  # Nombre de pics
        zero_crossings = len(np.where(np.diff(np.signbit(segment)))[0])  # Nombre de passages √† z√©ro
        
        # Regrouper toutes les caract√©ristiques
        feature_vec = np.array([
            mean, std, min_val, max_val, range_val, 
            gradient, abs_gradient, 
            dominant_freq_val, complexity,
            peak_count / max(1, seq_length), zero_crossings / max(1, seq_length)  # FIX: √âviter division par z√©ro
        ])
        
        features.append(feature_vec)
    
    return np.array(features)

# --- CR√âATION DE S√âQUENCES AVEC CARACT√âRISTIQUES ENRICHIES ---
def create_enriched_sequences(data, seq_length, pred_length=1, stride=1):
    """Cr√©e des s√©quences d'entr√©e/sortie avec des caract√©ristiques enrichies"""
    X_raw, y = [], []
    
    # FIX: V√©rifier que les donn√©es sont suffisantes
    if len(data) <= seq_length + pred_length:
        print(f"Warning: Data length {len(data)} is not sufficient for sequence length {seq_length} and prediction length {pred_length}")
        return np.array([]), np.array([]), np.array([])
    
    for i in range(0, len(data) - seq_length - pred_length + 1, stride):
        X_raw.append(data[i:i + seq_length])
        if pred_length == 1:
            y.append(data[i + seq_length])
        else:
            y.append(data[i + seq_length:i + seq_length + pred_length])
    
    X_raw = np.array(X_raw)
    
    # FIX: V√©rifier que X_raw n'est pas vide avant d'extraire les caract√©ristiques
    if len(X_raw) == 0:
        return np.array([]), np.array([]), np.array([])
    
    # Extraire des caract√©ristiques suppl√©mentaires
    X_features = extract_features(data, seq_length)
    
    # FIX: S'assurer que X_features et X_raw ont le m√™me nombre d'√©chantillons
    min_samples = min(len(X_raw), len(X_features))
    if min_samples == 0:
        return np.array([]), np.array([]), np.array([])
    
    X_raw = X_raw[:min_samples]
    X_features = X_features[:min_samples]
    y = np.array(y)[:min_samples]
    
    return X_raw, X_features, y

# Cr√©er des s√©quences avec caract√©ristiques enrichies
X_raw, X_features, y = create_enriched_sequences(eeg_sample, sequence_length, pred_length, stride)

# FIX: V√©rifier que les donn√©es ne sont pas vides
if len(X_raw) == 0 or len(X_features) == 0 or len(y) == 0:
    raise ValueError("Sequences could not be created. Check your data and parameters.")

X_raw = X_raw.reshape((X_raw.shape[0], X_raw.shape[1], 1))

print(f"Forme des donn√©es brutes: {X_raw.shape}")
print(f"Forme des caract√©ristiques: {X_features.shape}")
print(f"Forme des donn√©es de sortie: {y.shape}")

# Division en ensembles d'entra√Ænement et de test
train_size = int(len(X_raw) * 0.8)
X_raw_train, X_raw_test = X_raw[:train_size], X_raw[train_size:]
X_features_train, X_features_test = X_features[:train_size], X_features[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# FIX: V√©rifier qu'il y a suffisamment de donn√©es pour validation
if train_size < 5:
    raise ValueError(f"Not enough training data. Train size: {train_size}")

# Cr√©ation d'un ensemble de validation
val_size = max(1, int(train_size * 0.2))  # FIX: Au moins 1 √©chantillon pour validation
X_raw_val, X_features_val, y_val = X_raw_train[-val_size:], X_features_train[-val_size:], y_train[-val_size:]
X_raw_train, X_features_train, y_train = X_raw_train[:-val_size], X_features_train[:-val_size], y_train[:-val_size]

# --- MOD√àLE AVANC√â POUR EEG ---
def create_advanced_eeg_model(seq_length, feature_dim):
    """
    Mod√®le hybride optimis√© pour capturer la complexit√© des signaux EEG
    """
    # Entr√©e pour la s√©quence brute
    input_seq = Input(shape=(seq_length, 1))
    
    # Entr√©e pour les caract√©ristiques extraites
    input_features = Input(shape=(feature_dim,))
    
    # --- Branche de convolution multi-√©chelle ---
    # Ajouter du bruit subtil pour am√©liorer la g√©n√©ralisation
    x = GaussianNoise(0.005)(input_seq)
    
    # Convolutions parall√®les avec diff√©rentes tailles de noyau pour capturer diff√©rentes √©chelles
    conv_kernels = [2, 3, 5, 7]
    conv_outputs = []
    
    for kernel_size in conv_kernels:
        # FIX: S'assurer que kernel_size n'est pas plus grand que la s√©quence
        if kernel_size <= seq_length:
            conv = Conv1D(
                filters=32, 
                kernel_size=kernel_size,
                padding='same',
                activation='elu'  # ELU peut √™tre meilleur pour pr√©server les variations subtiles
            )(x)
            conv = LayerNormalization()(conv)  # Normalisation pour stabiliser l'entra√Ænement
            conv_outputs.append(conv)
    
    # FIX: V√©rifier qu'il y a des sorties de convolution
    if not conv_outputs:
        raise ValueError(f"All kernel sizes {conv_kernels} are larger than sequence length {seq_length}")
        
    # Concat√©ner les sorties de convolution
    x = Concatenate()(conv_outputs)
    
    # Convolutions dilat√©es pour capturer des d√©pendances √† long terme
    dilation_rates = [1, 2, 4, 8]
    dilated_outputs = []
    
    for dilation_rate in dilation_rates:
        # FIX: V√©rifier que la dilatation n'est pas trop grande pour la s√©quence
        if (3 - 1) * dilation_rate + 1 <= seq_length:  # Taille effective = (kernel_size - 1) * dilation_rate + 1
            dilated_conv = Conv1D(
                filters=32, 
                kernel_size=3, 
                padding='causal', 
                dilation_rate=dilation_rate,
                activation='elu'
            )(x)
            dilated_outputs.append(dilated_conv)
    
    # FIX: V√©rifier qu'il y a des sorties dilat√©es
    if not dilated_outputs:
        # Utiliser une convolution simple si aucune dilatation ne convient
        dilated_conv = Conv1D(
            filters=32, 
            kernel_size=1,  # Kernel size 1 fonctionnera toujours
            activation='elu'
        )(x)
        dilated_outputs.append(dilated_conv)
        
    # Combiner les convolutions dilat√©es
    x = Concatenate()(dilated_outputs)
    x = Conv1D(64, kernel_size=1, activation='elu')(x)  # R√©duction de dimension
    
    # --- Branche LSTM bidirectionnelle ---
    lstm_out = Bidirectional(LSTM(64, return_sequences=True))(x)
    lstm_out = LayerNormalization()(lstm_out)
    lstm_out = Dropout(0.3)(lstm_out)  # Dropout un peu plus √©lev√© pour √©viter le surapprentissage
    lstm_out = Bidirectional(LSTM(48, return_sequences=False))(lstm_out)
    
    # --- Traitement des caract√©ristiques ---
    # Passer les caract√©ristiques par des couches denses pour un meilleur apprentissage
    features_dense = Dense(32, activation='elu')(input_features)
    features_dense = Dense(32, activation='elu')(features_dense)
    
    # --- Fusion des branches ---
    combined = Concatenate()([lstm_out, features_dense])
    
    # Couches de sortie 
    x = Dense(64, activation='elu')(combined)
    x = Dropout(0.2)(x)
    x = Dense(32, activation='elu')(x)
    
    # Couche de sortie - pas d'activation pour la r√©gression
    output = Dense(pred_length)(x)
    
    # Cr√©er le mod√®le
    model = Model(inputs=[input_seq, input_features], outputs=output)
    
    # Optimiseur avec taux d'apprentissage adaptatif et clippage de gradient
    optimizer = Adam(learning_rate=0.001, clipnorm=1.0)
    model.compile(optimizer=optimizer, loss='mse')
    
    return model

# Cr√©er le mod√®le am√©lior√©
model = create_advanced_eeg_model(sequence_length, X_features.shape[1])
model.summary()

# Callbacks pour l'entra√Ænement avec sauvegarde et r√©duction du taux d'apprentissage
early_stopping = EarlyStopping(
    monitor='val_loss', 
    patience=15, 
    restore_best_weights=True,
    verbose=1
)
model_checkpoint = ModelCheckpoint(
    'best_eeg_model.keras', 
    save_best_only=True, 
    monitor='val_loss',
    verbose=1
)
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss', 
    factor=0.5, 
    patience=6, 
    min_lr=0.00001,
    verbose=1
)

# Entra√Ænement du mod√®le
history = model.fit(
    [X_raw_train, X_features_train], y_train,
    epochs=epochs,
    batch_size=batch_size,
    validation_data=([X_raw_val, X_features_val], y_val),
    callbacks=[early_stopping, model_checkpoint, reduce_lr],
    verbose=1
)

# Visualisation de la courbe d'apprentissage
plt.figure(figsize=(15, 5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('√âvolution de la perte pendant l\'entra√Ænement')
plt.xlabel('√âpoques')
plt.ylabel('Perte (MSE)')
plt.legend()
plt.grid(True)
plt.savefig('eeg_training_loss.png')
plt.close()

# FIX: V√©rifier qu'il y a des donn√©es de test avant de pr√©dire
if len(X_raw_test) == 0:
    raise ValueError("No test data available")

# Pr√©diction sur l'ensemble de test
y_pred = model.predict([X_raw_test, X_features_test])

# Inverser la normalisation pour obtenir les valeurs r√©elles
if pred_length == 1:
    y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
    y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()
else:
    y_test_inv = np.array([scaler.inverse_transform(y.reshape(-1, 1)).flatten() for y in y_test])
    y_pred_inv = np.array([scaler.inverse_transform(y.reshape(-1, 1)).flatten() for y in y_pred])

# Calcul de l'erreur
mse = mean_squared_error(y_test_inv, y_pred_inv)
rmse = np.sqrt(mse)
print(f"Erreur quadratique moyenne (MSE): {mse}")
print(f"Racine de l'erreur quadratique moyenne (RMSE): {rmse}")

# --- AM√âLIORATION MAJEURE: PR√âVISION R√âALISTE AVEC RECALCUL DES CARACT√âRISTIQUES ---
def forecast_realistic_eeg(model, initial_sequence, steps_ahead=200, scaler=None):
    """
    Pr√©vision r√©aliste de signal EEG qui recalcule les caract√©ristiques √† chaque √©tape
    et utilise une approche adaptative pour maintenir la naturalit√© du signal
    """
    sequence_length = initial_sequence.shape[0]
    future_predictions = []
    
    # S√©quence courante pour la pr√©diction it√©rative
    current_sequence = initial_sequence.flatten().copy()
    
    # FIX: V√©rifier qu'il y a assez de points dans la s√©quence
    if len(current_sequence) < 10:
        print(f"Warning: Initial sequence has only {len(current_sequence)} points, padding with zeros")
        padding = np.zeros(10 - len(current_sequence))
        current_sequence = np.concatenate([current_sequence, padding])
    
    # Historique r√©cent des variations pour maintenir la coh√©rence
    recent_variations = np.diff(current_sequence[-10:])
    variation_history = np.abs(recent_variations).mean()
    
    for i in range(steps_ahead):
        # FIX: V√©rifier que la s√©quence actuelle est de la bonne longueur
        if len(current_sequence) < sequence_length:
            padding = np.zeros(sequence_length - len(current_sequence))
            temp_sequence = np.concatenate([current_sequence, padding])
        else:
            temp_sequence = current_sequence[-sequence_length:]
        
        # Extraire les caract√©ristiques de la s√©quence actuelle
        try:
            # FIX: S'assurer que extract_features re√ßoit un tableau non vide
            if len(temp_sequence) == 0:
                raise ValueError("Empty sequence for feature extraction")
                
            current_features_array = extract_features(temp_sequence, sequence_length)
            
            # FIX: V√©rifier que les caract√©ristiques sont extraites correctement
            if len(current_features_array) == 0:
                raise ValueError("Feature extraction returned empty array")
                
            current_features = current_features_array[0]
        except Exception as e:
            print(f"Error extracting features: {e}")
            # Utiliser des caract√©ristiques par d√©faut
            current_features = np.zeros(X_features.shape[1])
        
        # Pr√©dire le prochain point
        next_point_scaled = model.predict(
            [temp_sequence.reshape(1, sequence_length, 1), 
             current_features.reshape(1, -1)]
        )[0][0]
        
        # Stabilit√© adaptative: si la pr√©diction s'√©carte trop de la tendance r√©cente,
        # appliquer une correction subtile
        last_point = current_sequence[-1]
        max_jump = 2.5 * variation_history  # Limite bas√©e sur la volatilit√© historique
        
        # Limiter les sauts trop grands tout en pr√©servant la direction
        if abs(next_point_scaled - last_point) > max_jump:
            direction = np.sign(next_point_scaled - last_point)
            next_point_scaled = last_point + direction * max_jump
        
        # Ajouter un peu de bruit adaptatif bas√© sur la volatilit√© du signal
        # Plus le signal √©tait volatile, plus on permet de fluctuations
        noise_scale = variation_history * 0.5  # La fluctuation est proportionnelle √† la volatilit√© historique
        # FIX: G√©rer le cas o√π variation_history est 0 ou NaN
        if not np.isfinite(noise_scale) or noise_scale == 0:
            noise_scale = 0.01  # Valeur par d√©faut
            
        noise = np.random.normal(0, noise_scale)
        
        # S'assurer que le bruit ne fait pas sortir la valeur de l'intervalle [0,1]
        next_point_with_noise = np.clip(next_point_scaled + noise, 0, 1)
        
        # Ajouter √† nos pr√©dictions
        future_predictions.append(next_point_with_noise)
        
        # Mettre √† jour la s√©quence pour la prochaine pr√©diction
        current_sequence = np.append(current_sequence[1:], next_point_with_noise)
        
        # Mettre √† jour l'historique des variations pour l'adaptativit√©
        if i >= 1:
            new_variation = abs(future_predictions[-1] - future_predictions[-2])
            # Moyenne mobile exponentielle pour l'historique des variations
            variation_history = 0.85 * variation_history + 0.15 * new_variation
    
    # Convertir les pr√©dictions en array numpy
    future_predictions = np.array(future_predictions)
    
    # Inverser la normalisation si un scaler est fourni
    if scaler is not None:
        future_predictions = scaler.inverse_transform(future_predictions.reshape(-1, 1)).flatten()
    
    return future_predictions

# FIX: V√©rifier qu'il y a des donn√©es de test avant de visualiser
if len(y_test_inv) < 100:
    print("Warning: Not enough test data for visualization. Using available data.")
    visualize_length = min(5, len(y_test_inv))
else:
    visualize_length = 5

# Visualiser quelques exemples de s√©quences r√©elles pour comprendre la variabilit√©
plt.figure(figsize=(15, 5))
for i in range(visualize_length):  # Afficher 5 s√©quences d'exemple (ou moins si pas assez de donn√©es)
    # FIX: S'assurer que l'index est valide
    max_start = max(0, len(y_test_inv) - 100)
    if max_start > 0:
        start_idx = np.random.randint(0, max_start)
        plot_length = min(100, len(y_test_inv) - start_idx)
        plt.plot(y_test_inv[start_idx:start_idx+plot_length], alpha=0.7)
    else:
        # Si pas assez de donn√©es, utiliser tout ce qui est disponible
        plt.plot(y_test_inv, alpha=0.7)

plt.title('Exemples de s√©quences EEG r√©elles (pour comprendre la variabilit√©)')
plt.xlabel('Points temporels')
plt.ylabel('Amplitude EEG')
plt.grid(True)
plt.savefig('eeg_real_patterns.png')
plt.close()

# FIX: V√©rifier qu'il y a des donn√©es de test avant de prendre la derni√®re s√©quence
if len(X_raw_test) > 0:
    # Prendre la derni√®re s√©quence comme point de d√©part
    last_known_sequence = X_raw_test[-1]
else:
    # S'il n'y a pas de donn√©es de test, utiliser la derni√®re s√©quence d'entra√Ænement
    last_known_sequence = X_raw_train[-1]

# Pr√©dire les points futurs avec la nouvelle m√©thode r√©aliste
future_steps = 200
future_predictions = forecast_realistic_eeg(model, last_known_sequence, future_steps, scaler)

# FIX: V√©rifier qu'il y a assez de donn√©es r√©elles pour la visualisation
if len(y_test_inv) < 100:
    real_history_length = len(y_test_inv)
    print(f"Warning: Only {real_history_length} real data points available for visualization")
else:
    real_history_length = 100

# Visualiser les pr√©dictions futures r√©alistes
plt.figure(figsize=(15, 6))

# Afficher les derni√®res valeurs r√©elles disponibles
real_history = y_test_inv[-real_history_length:]
plt.plot(range(real_history_length), real_history, label='Donn√©es EEG r√©elles', color='blue')

# Afficher les pr√©dictions futures
plt.plot(range(real_history_length-1, real_history_length-1+future_steps), future_predictions, 
         label='Pr√©dictions futures', color='red', linestyle='--')
plt.axvline(x=real_history_length-1, color='green', linestyle='-', label='Pr√©sent')

plt.title('Pr√©vision future r√©aliste du signal EEG')
plt.xlabel('Points temporels')
plt.ylabel('Amplitude EEG')
plt.legend()
plt.grid(True)
plt.savefig('eeg_future_realistic_forecast.png')

# Analyse suppl√©mentaire: comparer la distribution statistique
plt.figure(figsize=(12, 5))

# Configurer la grille pour deux graphiques c√¥te √† c√¥te
plt.subplot(1, 2, 1)
plt.hist(real_history, bins=20, alpha=0.7, label='Donn√©es r√©elles')
plt.hist(future_predictions, bins=20, alpha=0.7, label='Pr√©dictions')
plt.title('Distribution des valeurs')
plt.legend()

plt.subplot(1, 2, 2)
plt.hist(np.diff(real_history), bins=20, alpha=0.7, label='Diff√©rences r√©elles')
plt.hist(np.diff(future_predictions), bins=20, alpha=0.7, label='Diff√©rences pr√©dites')
plt.title('Distribution des variations point-√†-point')
plt.legend()

plt.tight_layout()
plt.savefig('eeg_distribution_comparison.png')
# Sauvegarder les pr√©dictions et les vraies valeurs dans un DataFrame
results_df = pd.DataFrame({
    'y_true': y_test_inv,
    'y_pred': y_pred_inv
})

# Sauvegarder dans un fichier CSV
results_df.to_csv('eeg_predictions.csv', index=False)

print("Les pr√©dictions ont √©t√© sauvegard√©es dans 'eeg_predictions.csv'")

print("Mod√®le de pr√©vision EEG am√©lior√© termin√©. Les graphiques ont √©t√© sauvegard√©s.")

====================================================================
Ou bien vous pouvez telecharger le model deja entrainer via le lien üëâ [T√©l√©charger le mod√®le (.keras)](https://drive.google.com/file/d/1ZKH9WgfoknVqFe2q4FvL_zb96o9EVRid/view?usp=sharing)
====================================================================
### Explication technique des composantes principales

#### 1. Extraction de caract√©ristiques avanc√©es
La fonction extract_features() calcule plusieurs m√©triques importantes sur les segments de signal EEG:

- *Caract√©ristiques statistiques*: moyenne, √©cart-type, minimum, maximum et amplitude du signal
- *Analyse de tendance*: calcul des gradients moyens pour d√©tecter les changements de direction
- *Analyse fr√©quentielle*: transform√©e de Fourier pour identifier les fr√©quences dominantes
- *Mesures de complexit√©*: calcul approximatif de l'entropie et des changements de direction
- *Forme d'onde*: d√©tection des pics et des passages par z√©ro pour caract√©riser l'oscillation

#### 2. Architecture du mod√®le hybride
Le mod√®le neuronal combine plusieurs approches compl√©mentaires:

- *Convolutions multi-√©chelles*: utilisation de noyaux de tailles vari√©es (2, 3, 5, 7) pour capturer diff√©rentes √©chelles temporelles
- *Convolutions dilat√©es*: permet de percevoir des d√©pendances √† long terme avec des taux de dilatation croissants (1, 2, 4, 8)
- *LSTM bidirectionnels*: analyse la s√©quence dans les deux directions temporelles pour mieux comprendre le contexte
- *Fusion multi-modalit√©*: combine les signaux bruts et les caract√©ristiques extraites pour une pr√©diction plus robuste

#### 3. Pr√©diction r√©aliste avec maintien de statistiques
La fonction forecast_realistic_eeg() propose une m√©thode avanc√©e pour g√©n√©rer des pr√©dictions futures:

- *Pr√©diction adaptative*: recalcule les caract√©ristiques √† chaque pas de temps pour plus de pr√©cision
- *Stabilit√© statistique*: limite les variations excessives en fonction de l'historique de volatilit√©
- *Bruit coh√©rent*: ajoute un bruit adaptatif pour maintenir la naturalit√© du signal
- *Moyenne mobile exponentielle*: met √† jour dynamiquement l'estimation de la volatilit√©

### R√©sultats et visualisations
Le code g√©n√®re plusieurs visualisations pour √©valuer la qualit√© des pr√©dictions:

1. Courbe d'apprentissage montrant l'√©volution de la perte d'entra√Ænement et de validation
2. √âchantillons de s√©quences EEG r√©elles pour comprendre la variabilit√© naturelle
3. Pr√©diction future avec comparaison aux donn√©es historiques

6. D√©tection des troubles du sommeil
-----------------------------------

Cette section finale combine les analyses des signaux EEG et EMG pour identifier les troubles du sommeil.

*Code √† ex√©cuter* :


*R√©sultat attendu* :
- Graphique √† barres montrant les probabilit√©s de chaque trouble
- Visualisation des segments de signaux EEG et EMG
- Hypnogramme approximatif des stades de sommeil

Conseils d'optimisation
======================

Pour obtenir les meilleurs r√©sultats :

1. *Qualit√© des donn√©es* :

   - Utilisez des enregistrements PSG complets (8h minimum)
   - V√©rifiez que les signaux EEG et EMG sont clairement identifi√©s
   - Pr√©f√©rez les fichiers `.edf` standardis√©s (ex : Sleep-EDF database)

2. *Ajustement des param√®tres du mod√®le* :

   - Augmentez le nombre d'√©poques pour un meilleur apprentissage
   - Testez diff√©rentes architectures LSTM (couches, unit√©s)
   - Variez la taille des s√©quences d'entr√©e

3. *Adaptation des seuils de d√©tection* :

   - Ajustez les seuils selon la sensibilit√© souhait√©e
   - Pour un d√©pistage large : r√©duisez les seuils
   - Pour minimiser les faux positifs : augmentez les seuils

D√©pannage
========

Probl√®mes courants et solutions
------------------------------

1. **Erreur lors du chargement du fichier `.edf`** :

   - *Probl√®me*: MNE ne peut pas lire certains canaux
   - *Solution*: V√©rifiez les noms des canaux avec `raw.ch_names` et ajustez le code

2. *Erreurs de pr√©diction* :

   - *Probl√®me*: Mod√®le peu performant (MSE √©lev√©)
   - *Solution*: Augmentez les donn√©es d'entra√Ænement ou essayez d'autres architectures de mod√®le

3. *M√©moire insuffisante* :

   - *Probl√®me*: Erreur de m√©moire lors du traitement des grands fichiers
   - *Solution*: R√©duisez la taille des batchs ou sous-√©chantillonnez les donn√©es

4. *Format de donn√©es incompatible* :

   - *Probl√®me*: Structure de fichier EDF non standard
   - *Solution*: Utilisez des outils de conversion comme EDFbrowser avant l'importation

Ressources suppl√©mentaires
=========================

- Sleep-EDF Database: https://physionet.org/content/sleep-edfx/1.0.0/
- Documentation MNE-Python: https://mne.tools/stable/index.html
- Tutoriel d'analyse du sommeil avec Python: https://raphaelvallat.com/yasa/build/html/index.html

Support
======

Si vous rencontrez des probl√®mes avec le notebook :

- Consultez les forums Kaggle pour des solutions similaires